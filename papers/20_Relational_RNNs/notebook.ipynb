{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Day 20: Relational Recurrent Neural Networks (RMC)\n",
                "\n",
                "## Interactive Walkthrough\n",
                "\n",
                "In this notebook, we will:\n",
                "1.  **Build an RMC** from scratch (concept filters).\n",
                "2.  ** Visualize** how the memory slots interact using Self-Attention.\n",
                "3.  **Compare** RMC vs. LSTM on the \"N-th Farthest\" task.\n",
                "\n",
                "### Why this matters\n",
                "Standard RNNs (like LSTMs) have a \"bottleneck\" problem: they try to cram everything into a single vector. RMC splits memory into **slots** that can talk to each other."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "# Import our implementation\n",
                "from implementation import RelationalMemory, StandardLSTM\n",
                "from visualization import plot_attention_heatmap"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. The Relational Memory Core\n",
                "\n",
                "Let's initialize a small RMC with 4 memory slots."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "INPUT_SIZE = 16\n",
                "MEM_SLOTS = 4\n",
                "MEM_SIZE = 32\n",
                "HEADS = 4\n",
                "\n",
                "rmc = RelationalMemory(mem_slots=MEM_SLOTS, \n",
                "                       mem_size=MEM_SIZE, \n",
                "                       input_size=INPUT_SIZE, \n",
                "                       num_heads=HEADS)\n",
                "\n",
                "print(f\"RMC Created with {MEM_SLOTS} slots of size {MEM_SIZE}.\")\n",
                "print(f\"Total Parameters: {sum(p.numel() for p in rmc.parameters())}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Visualizing Self-Attention\n",
                "\n",
                "RMC is special because it uses **attention** internally. Let's feed it some random data and see the attention weights."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a random input sequence\n",
                "batch_size = 1\n",
                "seq_len = 10\n",
                "inputs = torch.randn(batch_size, seq_len, INPUT_SIZE)\n",
                "\n",
                "# Run manually step-by-step to capture attention\n",
                "memory = None\n",
                "attention_history = []\n",
                "\n",
                "for t in range(seq_len):\n",
                "    input_step = inputs[:, t, :]\n",
                "    memory, probs = rmc(input_step, memory)\n",
                "    attention_history.append(probs)\n",
                "\n",
                "# Stack: (seq, batch, heads, slots, slots)\n",
                "attn_stack = torch.stack(attention_history, dim=0).squeeze(1)\n",
                "\n",
                "# Plot\n",
                "plot_attention_heatmap(attn_stack, \"notebook_attention.png\")\n",
                "\n",
                "# Display (using markdown for image)\n",
                "from IPython.display import Image\n",
                "display(Image(\"notebook_attention.png\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. RMC vs LSTM Comparison\n",
                "\n",
                "Now let's verify if RMC actually learns differently. We'll check the parameters of a comparable LSTM."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lstm = StandardLSTM(input_size=INPUT_SIZE, hidden_size=64, output_size=INPUT_SIZE)\n",
                "\n",
                "print(f\"LSTM Parameters: {sum(p.numel() for p in lstm.parameters())}\")\n",
                "print(\"Note: We try to keep parameter counts roughly similar for fair comparison.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Run Training\n",
                "\n",
                "To train the models, run the script in the terminal:\n",
                "\n",
                "```bash\n",
                "python train_minimal.py --model both --visualize\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}