{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Day 6: The First Law of Complexodynamics\n","\n","> Scott Aaronson (2011) - [Blog Post](https://scottaaronson.blog/?p=762)\n","\n","**Core question:** Why does \"interestingness\" peak at intermediate times while entropy monotonically increases?\n","\n","**Aaronson's answer:** Complextropy (resource-bounded sophistication) should be small early, large middle, small late.\n","\n","In this notebook we build the coffee mixing simulation and measure multiple complexity proxies."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\nimport gzip\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (10, 6)"]},{"cell_type":"markdown","metadata":{},"source":["## 1. KC Approximation via gzip\n","Kolmogorov complexity is uncomputable. gzip gives a useful upper bound."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def gzip_complexity(data: bytes) -> int:\n    return len(gzip.compress(data, compresslevel=9))\n\nzeros = bytes(1024)\nrandom_data = np.random.randint(0, 256, 1024, dtype=np.uint8).tobytes()\npattern = b'ABCD' * 256\n\nprint(f'All zeros:  {gzip_complexity(zeros)} bytes')\nprint(f'Pattern:    {gzip_complexity(pattern)} bytes')\nprint(f'Random:     {gzip_complexity(random_data)} bytes')"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Coffee Mixing Simulation\n","2D pixel grid: top half black (coffee), bottom half white (milk). Random neighbor swaps."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_grid(size=64):\n    grid = np.zeros((size, size), dtype=np.uint8)\n    grid[:size//2, :] = 1\n    return grid\n\ndef batch_swap(grid, n_swaps=100):\n    rows, cols = grid.shape\n    for _ in range(n_swaps):\n        r, c = np.random.randint(rows), np.random.randint(cols)\n        d = np.random.randint(4)\n        if d == 0 and r > 0: nr, nc = r-1, c\n        elif d == 1 and r < rows-1: nr, nc = r+1, c\n        elif d == 2 and c > 0: nr, nc = r, c-1\n        elif d == 3 and c < cols-1: nr, nc = r, c+1\n        else: continue\n        if grid[r, c] != grid[nr, nc]:\n            grid[r, c], grid[nr, nc] = grid[nr, nc], grid[r, c]\n    return grid\n\ngrid = create_grid(64)\nplt.imshow(grid, cmap='gray', interpolation='nearest')\nplt.title('Initial: separated coffee and milk')\nplt.axis('off'); plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Watch Mixing\n","Separated (simple) -> Tendrils (complex) -> Uniform (simple)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.random.seed(42)\ngrid = create_grid(64)\nsnapshots = [(0, grid.copy())]\nn_steps = 800\nfor step in range(1, n_steps + 1):\n    batch_swap(grid, 50)\n    if step % 160 == 0:\n        snapshots.append((step * 50, grid.copy()))\n\nfig, axes = plt.subplots(1, len(snapshots), figsize=(3*len(snapshots), 3))\nfor ax, (t, g) in zip(axes, snapshots):\n    ax.imshow(g, cmap='gray', interpolation='nearest')\n    ax.set_title(f't={t:,}'); ax.axis('off')\nfig.suptitle('Coffee Mixing Progression'); plt.tight_layout(); plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## 4. The Complexity Hump\n","Track gzip complexity over time: should increase then decrease."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.random.seed(42)\ngrid = create_grid(64)\ntimes, complexities = [0], [gzip_complexity(grid.tobytes())]\n\nfor step in range(1, 1001):\n    batch_swap(grid, 50)\n    if step % 10 == 0:\n        times.append(step * 50)\n        complexities.append(gzip_complexity(grid.tobytes()))\n\npeak_idx = np.argmax(complexities)\nplt.plot(times, complexities, 'r-', lw=2)\nplt.plot(times[peak_idx], complexities[peak_idx], 'ko', ms=10)\nplt.xlabel('Total swaps'); plt.ylabel('gzip size (bytes)')\nplt.title('THE COMPLEXITY HUMP'); plt.grid(True, alpha=0.3); plt.show()\nprint(f'Peak at swap {times[peak_idx]:,}: {complexities[peak_idx]} bytes')"]},{"cell_type":"markdown","metadata":{},"source":["## 5. Entropy vs Complexity\n","Entropy monotonically increases. Complexity peaks. This is what Aaronson wants to formalize."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def local_entropy(grid, w=8):\n    h, width = grid.shape\n    vals = []\n    for i in range(0, h-w, w//2):\n        for j in range(0, width-w, w//2):\n            p = grid[i:i+w, j:j+w].mean()\n            if 0 < p < 1:\n                vals.append(-(p*np.log2(p)+(1-p)*np.log2(1-p)))\n            else: vals.append(0.0)\n    return np.mean(vals)\n\nnp.random.seed(42)\ngrid = create_grid(64)\ntimes, kc_vals, ent_vals = [0], [gzip_complexity(grid.tobytes())], [local_entropy(grid)]\nfor step in range(1, 1001):\n    batch_swap(grid, 50)\n    if step % 10 == 0:\n        times.append(step*50)\n        kc_vals.append(gzip_complexity(grid.tobytes()))\n        ent_vals.append(local_entropy(grid))\n\nfig, axes = plt.subplots(1, 2, figsize=(13, 5))\naxes[0].plot(times, ent_vals, 'b-', lw=2); axes[0].set_title('Local Entropy (monotone)')\naxes[1].plot(times, kc_vals, 'r-', lw=2); axes[1].set_title('Complexity (hump)')\nfor ax in axes: ax.set_xlabel('Swaps'); ax.grid(True, alpha=0.3)\nplt.suptitle('Entropy vs Complexity'); plt.tight_layout(); plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Summary\n","\n","- Entropy increases monotonically\n","- gzip complexity shows the hump at intermediate times\n","- Aaronson conjectures complextropy must provably peak (unproven as of 2024)\n","- Day 7 empirically tests these measures on the Coffee Automaton"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.0"}},"nbformat":4,"nbformat_minor":4}
