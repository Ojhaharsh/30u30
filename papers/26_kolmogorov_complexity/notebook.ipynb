{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 26: Kolmogorov Complexity & Algorithmic Randomness\n",
    "\n",
    "Day 26 of 30 Papers in 30 Days.\n",
    "\n",
    "Today: **Kolmogorov Complexity ($C(x)$)** â€” the ultimate measure of information content. While Shannon entropy tells us about the source, Kolmogorov tells us about the object itself.\n",
    "\n",
    "## What We'll Do\n",
    "\n",
    "1. **The Problem**: why statistical entropy isn't enough\n",
    "2. **The Solution**: Compression as a proxy for intelligence\n",
    "3. **The Walkthrough**: Building a Huffman Tree bit-by-bit\n",
    "4. **The conveyor belt**: Arithmetic Interval Shrinkage\n",
    "5. **Similarity without Models**: Clusterting with NCD\n",
    "6. **The Incompressibility Proof**: Why most noise stays noise\n",
    "\n",
    "## The Core Insight\n",
    "\n",
    "The complexity of a string is the length of the shortest program that produces it. Understanding is the process of finding that program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# Import our implementations\n",
    "from implementation import HuffmanCoder, ArithmeticCoder, ComplexityMetrics\n",
    "\n",
    "h_coder = HuffmanCoder()\n",
    "a_coder = ArithmeticCoder()\n",
    "\n",
    "print(\"All imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Problem: Intelligence as Compression\n",
    "\n",
    "Shannon Information theory (1948) deals with transmission over noisy channels. It assumes data comes from a known 'distribution'.\n",
    "\n",
    "But what if we have a single, fixed object? Like a DNA sequence or a file? \n",
    "\n",
    "**AIT Insight:** The information in $x$ is the length of the shortest description of $x$. If you understand the physics of a system, you can write a short simulation that produces its history. If you don't, you just have a list of random facts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Walkthrough: Huffman Step-by-Step\n",
    "\n",
    "Huffman coding is a greedy algorithm. Let's watch it build a tree for the word `\"KOLMOGOROV\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"KOLMOGOROV\"\n",
    "freqs = Counter(text)\n",
    "print(f\"Frequencies: {dict(freqs)}\")\n",
    "\n",
    "# Visualize the sorted frequencies (The foundation of the tree)\n",
    "labels, values = zip(*sorted(freqs.items(), key=lambda x: x[1]))\n",
    "plt.bar(labels, values, color='#6d597a')\n",
    "plt.title(\"Character Frequencies in 'KOLMOGOROV'\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "codes = h_coder.generate_codes(text)\n",
    "print(\"\\nGenerated Prefix Codes:\")\n",
    "for char in sorted(codes.keys()):\n",
    "    print(f\"  '{char}': {codes[char]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Conveyor Belt: Arithmetic Range Updates\n",
    "\n",
    "Instead of mapping chars to bits, Arithmetic coding maps the entire sequence to a number in $[0, 1)$. We treat character probabilities as sub-intervals on a 'conveyor belt' that we zoom into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_arithmetic(text):\n",
    "    low, high = 0.0, 1.0\n",
    "    # Simple uniform-ish probability for demonstration\n",
    "    chars = sorted(list(set(text)))\n",
    "    p = 1.0 / len(chars)\n",
    "    char_ranges = {c: (i*p, (i+1)*p) for i, c in enumerate(chars)}\n",
    "    \n",
    "    print(f\"{'Char':5} | {'Low':10} | {'High':10} | {'Range'}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for char in text[:6]: # Just first 6 for visibility\n",
    "        p_low, p_high = char_ranges[char]\n",
    "        width = high - low\n",
    "        high = low + width * p_high\n",
    "        low = low + width * p_low\n",
    "        print(f\"{char:5} | {low:10.8f} | {high:10.8f} | {high-low:10.8f}\")\n",
    "\n",
    "trace_arithmetic(\"KOLMOGOROV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Complexity Spectrum\n",
    "\n",
    "We compare strings of equal length but different structure. $C(x)$ should be low for constant strings and high for random ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 500\n",
    "constant = \"a\" * length\n",
    "periodic = \"abcde\" * (length // 5)\n",
    "random_str = \"\".join(random.choices(string.ascii_lowercase, k=length))\n",
    "\n",
    "for name, s in [(\"Constant\", constant), (\"Periodic\", periodic), (\"Random\", random_str)]:\n",
    "    bits = h_coder.get_complexity(s)\n",
    "    ratio = bits / (length * 8)\n",
    "    print(f\"{name:12} | Compressed Bits: {bits:5} | Ratio: {ratio:5.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Similarity Without Models (NCD)\n",
    "\n",
    "NCD measures similarity by checking if $C(xy)$ is smaller than $C(x) + C(y)$. If strings share patterns, their joint complexity drops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math1 = \"Prime numbers are only divisible by one and themselves.\"\n",
    "math2 = \"There is no largest prime number; the set is infinite.\"\n",
    "code1 = \"for i in range(10): print(i**2)\"\n",
    "\n",
    "comp = lambda x: h_coder.get_complexity(x)\n",
    "print(f\"NCD(Math 1, Math 2): {ComplexityMetrics.ncd(math1, math2, comp):.3f} (Lower = More Similar)\")\n",
    "print(f\"NCD(Math 1, Code 1): {ComplexityMetrics.ncd(math1, code1, comp):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "1. **Intelligence = Compression**: The ability to find regularities in data and represent them as short programs.\n",
    "2. **The Bottleneck**: $C(x)$ is the theoretical limit of how much we can compress an object.\n",
    "3. **Randomness**: A string is random if its shortest description is as long as the string itself.\n",
    "\n",
    "### Next Steps\n",
    "- Solve the **Incompressibility Challenge** in `exercises/exercise_05_incompressibility.py`.\n",
    "- Explore the **Paper Notes** for the deep mathematical proofs from the Moscow School."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
