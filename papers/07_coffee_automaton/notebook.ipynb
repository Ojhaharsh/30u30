{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b32527b5",
   "metadata": {},
   "source": [
    "# Day 7: Coffee Automaton - Interactive Complexity Dynamics Exploration\n",
    "\n",
    "*\"Understanding how complexity emerges from simple rules through the lens of a cooling coffee cup\"*\n",
    "\n",
    "This interactive notebook explores complexity theory through the Coffee Automaton model, demonstrating how simple local rules can generate rich, emergent behaviors that mirror fundamental principles in AI and physics.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand complexity emergence from simple rules\n",
    "- Explore entropy dynamics in computational systems  \n",
    "- Analyze phase transitions and critical phenomena\n",
    "- Connect complexity theory to modern AI architectures\n",
    "- Visualize the \"sweet spot\" where complexity thrives\n",
    "\n",
    "Let's begin our journey into the fascinating world of complexity dynamics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86627c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our custom implementations\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "from implementation import CoffeeAutomaton, ComplexityMeasures, LifeAnalyzer\n",
    "from visualization import CoffeeAutomatonVisualizer\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üî¨ Coffee Automaton Interactive Lab Ready!\")\n",
    "print(\"üìä All libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b94a98",
   "metadata": {},
   "source": [
    "## Part 1: Understanding the Coffee Automaton\n",
    "\n",
    "The Coffee Automaton models how a coffee cup cools down through cellular automata rules. Each cell represents a small region of coffee, and the temperature evolves according to:\n",
    "\n",
    "**Heat Diffusion Rule**: \n",
    "```\n",
    "T_new[i,j] = T_old[i,j] + Œ± √ó (Œ£T_neighbors - 4√óT_old[i,j]) + noise\n",
    "```\n",
    "\n",
    "**Environmental Cooling**: \n",
    "```\n",
    "T_new[i,j] = T_new[i,j] √ó (1 - cooling_rate)\n",
    "```\n",
    "\n",
    "Let's create our first coffee automaton and watch it evolve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a3f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a basic coffee automaton\n",
    "def create_coffee_demo(size=50, initial_temp=100.0):\n",
    "    \"\"\"Create and display a basic coffee automaton.\"\"\"\n",
    "    \n",
    "    # Initialize the automaton\n",
    "    coffee = CoffeeAutomaton(size=size, initial_temp=initial_temp)\n",
    "    \n",
    "    print(f\"‚òï Created {size}√ó{size} coffee automaton\")\n",
    "    print(f\"üå°Ô∏è Initial temperature: {initial_temp}¬∞C\")\n",
    "    print(f\"‚ùÑÔ∏è Environment temperature: {coffee.environment_temp}¬∞C\")\n",
    "    \n",
    "    # Run a few steps and show the evolution\n",
    "    temps = []\n",
    "    complexities = []\n",
    "    entropies = []\n",
    "    \n",
    "    for step in range(20):\n",
    "        temps.append(coffee.grid.mean())\n",
    "        \n",
    "        # Calculate complexity metrics\n",
    "        complexity_calc = ComplexityMeasures()\n",
    "        complexity = complexity_calc.calculate_local_complexity(coffee.grid)\n",
    "        entropy = complexity_calc.calculate_entropy(coffee.grid)\n",
    "        \n",
    "        complexities.append(complexity.mean())\n",
    "        entropies.append(entropy)\n",
    "        \n",
    "        coffee.step()\n",
    "    \n",
    "    # Plot the evolution\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # Temperature evolution\n",
    "    ax1.plot(temps, 'r-o', linewidth=2, markersize=6)\n",
    "    ax1.set_xlabel('Time Steps')\n",
    "    ax1.set_ylabel('Average Temperature (¬∞C)')\n",
    "    ax1.set_title('Coffee Cooling Dynamics')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Complexity evolution  \n",
    "    ax2.plot(complexities, 'b-s', linewidth=2, markersize=6)\n",
    "    ax2.set_xlabel('Time Steps')\n",
    "    ax2.set_ylabel('Local Complexity')\n",
    "    ax2.set_title('Complexity Emergence')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Entropy evolution\n",
    "    ax3.plot(entropies, 'g-^', linewidth=2, markersize=6)\n",
    "    ax3.set_xlabel('Time Steps')\n",
    "    ax3.set_ylabel('System Entropy')\n",
    "    ax3.set_title('Information Dynamics')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Final temperature distribution\n",
    "    im = ax4.imshow(coffee.grid, cmap='hot', interpolation='bilinear')\n",
    "    ax4.set_title('Final Temperature Distribution')\n",
    "    plt.colorbar(im, ax=ax4, label='Temperature (¬∞C)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return coffee\n",
    "\n",
    "# Create and run demo\n",
    "demo_coffee = create_coffee_demo(size=40, initial_temp=95.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c4ba4e",
   "metadata": {},
   "source": [
    "## Part 2: Interactive Parameter Exploration\n",
    "\n",
    "Now let's create interactive widgets to explore how different parameters affect the coffee automaton's behavior. This is where the magic happens - we'll see how small changes can lead to dramatically different complexity patterns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7191b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive parameter exploration\n",
    "def explore_parameters(diffusion_rate=0.1, cooling_rate=0.02, noise_level=0.01, size=30):\n",
    "    \"\"\"Interactive exploration of coffee automaton parameters.\"\"\"\n",
    "    \n",
    "    # Create automaton with custom parameters\n",
    "    coffee = CoffeeAutomaton(\n",
    "        size=size, \n",
    "        initial_temp=100.0,\n",
    "        diffusion_rate=diffusion_rate,\n",
    "        cooling_rate=cooling_rate,\n",
    "        noise_level=noise_level\n",
    "    )\n",
    "    \n",
    "    # Run simulation\n",
    "    steps = 30\n",
    "    metrics = {'temp': [], 'complexity': [], 'entropy': []}\n",
    "    grids = []\n",
    "    \n",
    "    complexity_calc = ComplexityMeasures()\n",
    "    \n",
    "    for step in range(steps):\n",
    "        # Store metrics\n",
    "        metrics['temp'].append(coffee.grid.mean())\n",
    "        \n",
    "        complexity = complexity_calc.calculate_local_complexity(coffee.grid)\n",
    "        metrics['complexity'].append(complexity.mean())\n",
    "        \n",
    "        entropy = complexity_calc.calculate_entropy(coffee.grid)\n",
    "        metrics['entropy'].append(entropy)\n",
    "        \n",
    "        # Store grid snapshots\n",
    "        if step % 10 == 0:\n",
    "            grids.append(coffee.grid.copy())\n",
    "        \n",
    "        coffee.step()\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Metrics evolution\n",
    "    time_steps = range(steps)\n",
    "    ax1.plot(time_steps, metrics['temp'], 'r-', linewidth=2, label='Temperature')\n",
    "    ax1_twin = ax1.twinx()\n",
    "    ax1_twin.plot(time_steps, metrics['complexity'], 'b-', linewidth=2, label='Complexity')\n",
    "    ax1_twin.plot(time_steps, metrics['entropy'], 'g-', linewidth=2, label='Entropy')\n",
    "    \n",
    "    ax1.set_xlabel('Time Steps')\n",
    "    ax1.set_ylabel('Temperature (¬∞C)', color='red')\n",
    "    ax1_twin.set_ylabel('Complexity / Entropy', color='blue')\n",
    "    ax1.set_title(f'System Evolution (diff={diffusion_rate:.3f}, cool={cooling_rate:.3f})')\n",
    "    \n",
    "    # Temperature distributions at different times\n",
    "    for i, (grid, step) in enumerate(zip(grids, [0, 10, 20])):\n",
    "        ax = [ax2, ax3, ax4][i]\n",
    "        im = ax.imshow(grid, cmap='hot', interpolation='bilinear', vmin=0, vmax=100)\n",
    "        ax.set_title(f'Step {step}')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print insights\n",
    "    max_complexity = max(metrics['complexity'])\n",
    "    max_complexity_step = metrics['complexity'].index(max_complexity)\n",
    "    \n",
    "    print(f\"üìä Parameter Analysis:\")\n",
    "    print(f\"   Diffusion Rate: {diffusion_rate:.3f}\")\n",
    "    print(f\"   Cooling Rate: {cooling_rate:.3f}\")\n",
    "    print(f\"   Noise Level: {noise_level:.3f}\")\n",
    "    print(f\"   Peak Complexity: {max_complexity:.3f} at step {max_complexity_step}\")\n",
    "    print(f\"   Final Temperature: {metrics['temp'][-1]:.2f}¬∞C\")\n",
    "\n",
    "# Create interactive widget\n",
    "interact(explore_parameters,\n",
    "         diffusion_rate=widgets.FloatSlider(min=0.01, max=0.5, step=0.01, value=0.1, description='Diffusion:'),\n",
    "         cooling_rate=widgets.FloatSlider(min=0.001, max=0.1, step=0.001, value=0.02, description='Cooling:'),\n",
    "         noise_level=widgets.FloatSlider(min=0.0, max=0.05, step=0.001, value=0.01, description='Noise:'),\n",
    "         size=widgets.IntSlider(min=20, max=60, step=10, value=30, description='Grid Size:'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb0324",
   "metadata": {},
   "source": [
    "## Part 3: The Complexity Sweet Spot\n",
    "\n",
    "One of the most fascinating discoveries in complexity science is the existence of a \"sweet spot\" - parameter regimes where complexity is maximized. This occurs at the edge of chaos, between order and disorder.\n",
    "\n",
    "Let's systematically explore this sweet spot in our coffee automaton!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec1335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Systematic exploration of the complexity landscape\n",
    "def find_complexity_landscape():\n",
    "    \"\"\"Map the complexity landscape across parameter space.\"\"\"\n",
    "    \n",
    "    print(\"üîç Mapping complexity landscape... (this may take a moment)\")\n",
    "    \n",
    "    # Parameter ranges to explore\n",
    "    diffusion_rates = np.linspace(0.05, 0.3, 8)\n",
    "    cooling_rates = np.linspace(0.01, 0.08, 8)\n",
    "    \n",
    "    complexity_map = np.zeros((len(cooling_rates), len(diffusion_rates)))\n",
    "    entropy_map = np.zeros((len(cooling_rates), len(diffusion_rates)))\n",
    "    \n",
    "    complexity_calc = ComplexityMeasures()\n",
    "    \n",
    "    for i, cooling in enumerate(cooling_rates):\n",
    "        for j, diffusion in enumerate(diffusion_rates):\n",
    "            # Create automaton with these parameters\n",
    "            coffee = CoffeeAutomaton(\n",
    "                size=25,  # Smaller for speed\n",
    "                diffusion_rate=diffusion,\n",
    "                cooling_rate=cooling,\n",
    "                noise_level=0.01\n",
    "            )\n",
    "            \n",
    "            # Run simulation and collect metrics\n",
    "            complexities = []\n",
    "            entropies = []\n",
    "            \n",
    "            for step in range(25):\n",
    "                complexity = complexity_calc.calculate_local_complexity(coffee.grid)\n",
    "                entropy = complexity_calc.calculate_entropy(coffee.grid)\n",
    "                \n",
    "                complexities.append(complexity.mean())\n",
    "                entropies.append(entropy)\n",
    "                \n",
    "                coffee.step()\n",
    "            \n",
    "            # Store peak complexity and entropy\n",
    "            complexity_map[i, j] = max(complexities)\n",
    "            entropy_map[i, j] = max(entropies)\n",
    "    \n",
    "    # Visualize the landscape\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Complexity landscape\n",
    "    im1 = ax1.imshow(complexity_map, cmap='viridis', aspect='auto', origin='lower')\n",
    "    ax1.set_xticks(range(len(diffusion_rates)))\n",
    "    ax1.set_yticks(range(len(cooling_rates)))\n",
    "    ax1.set_xticklabels([f'{d:.2f}' for d in diffusion_rates])\n",
    "    ax1.set_yticklabels([f'{c:.3f}' for c in cooling_rates])\n",
    "    ax1.set_xlabel('Diffusion Rate')\n",
    "    ax1.set_ylabel('Cooling Rate')\n",
    "    ax1.set_title('Complexity Landscape')\n",
    "    plt.colorbar(im1, ax=ax1, label='Peak Complexity')\n",
    "    \n",
    "    # Entropy landscape\n",
    "    im2 = ax2.imshow(entropy_map, cmap='plasma', aspect='auto', origin='lower')\n",
    "    ax2.set_xticks(range(len(diffusion_rates)))\n",
    "    ax2.set_yticks(range(len(cooling_rates)))\n",
    "    ax2.set_xticklabels([f'{d:.2f}' for d in diffusion_rates])\n",
    "    ax2.set_yticklabels([f'{c:.3f}' for c in cooling_rates])\n",
    "    ax2.set_xlabel('Diffusion Rate')\n",
    "    ax2.set_ylabel('Cooling Rate')\n",
    "    ax2.set_title('Entropy Landscape')\n",
    "    plt.colorbar(im2, ax=ax2, label='Peak Entropy')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find the sweet spots\n",
    "    max_complexity_idx = np.unravel_index(complexity_map.argmax(), complexity_map.shape)\n",
    "    max_entropy_idx = np.unravel_index(entropy_map.argmax(), entropy_map.shape)\n",
    "    \n",
    "    print(f\"üéØ Sweet Spot Analysis:\")\n",
    "    print(f\"   Maximum Complexity: {complexity_map.max():.3f}\")\n",
    "    print(f\"     at diffusion={diffusion_rates[max_complexity_idx[1]]:.3f}, cooling={cooling_rates[max_complexity_idx[0]]:.3f}\")\n",
    "    print(f\"   Maximum Entropy: {entropy_map.max():.3f}\")\n",
    "    print(f\"     at diffusion={diffusion_rates[max_entropy_idx[1]]:.3f}, cooling={cooling_rates[max_entropy_idx[0]]:.3f}\")\n",
    "    \n",
    "    return diffusion_rates[max_complexity_idx[1]], cooling_rates[max_complexity_idx[0]]\n",
    "\n",
    "# Find the sweet spot\n",
    "optimal_diffusion, optimal_cooling = find_complexity_landscape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6b630",
   "metadata": {},
   "source": [
    "## Part 4: Life in the Coffee Cup\n",
    "\n",
    "Now let's explore the fascinating emergence of \"life-like\" patterns in our coffee automaton. These patterns exhibit characteristics similar to Conway's Game of Life but emerge from physical heat diffusion rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff7d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore life-like patterns in optimal conditions\n",
    "def explore_coffee_life(diffusion_rate, cooling_rate):\n",
    "    \"\"\"Explore life-like patterns in the coffee automaton.\"\"\"\n",
    "    \n",
    "    print(f\"üî¨ Exploring life patterns with optimal parameters:\")\n",
    "    print(f\"   Diffusion: {diffusion_rate:.3f}, Cooling: {cooling_rate:.3f}\")\n",
    "    \n",
    "    # Create automaton with optimal parameters\n",
    "    coffee = CoffeeAutomaton(\n",
    "        size=40,\n",
    "        diffusion_rate=diffusion_rate,\n",
    "        cooling_rate=cooling_rate,\n",
    "        noise_level=0.015  # Slightly higher noise for pattern formation\n",
    "    )\n",
    "    \n",
    "    # Add some \"seeds\" for pattern formation\n",
    "    coffee.add_hotspot(15, 15, intensity=20, radius=3)\n",
    "    coffee.add_hotspot(25, 25, intensity=25, radius=2)\n",
    "    coffee.add_hotspot(20, 30, intensity=15, radius=4)\n",
    "    \n",
    "    life_analyzer = LifeAnalyzer()\n",
    "    \n",
    "    # Run simulation and analyze patterns\n",
    "    grids = []\n",
    "    life_metrics = []\n",
    "    \n",
    "    for step in range(50):\n",
    "        # Store grid\n",
    "        if step % 5 == 0:\n",
    "            grids.append(coffee.grid.copy())\n",
    "        \n",
    "        # Analyze life-like behavior\n",
    "        metrics = life_analyzer.analyze_step(coffee.grid)\n",
    "        life_metrics.append(metrics)\n",
    "        \n",
    "        coffee.step()\n",
    "    \n",
    "    # Visualize the evolution\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "    \n",
    "    # Show grid evolution\n",
    "    for i, grid in enumerate(grids):\n",
    "        ax = axes[0, i]\n",
    "        im = ax.imshow(grid, cmap='hot', interpolation='nearest', vmin=0, vmax=100)\n",
    "        ax.set_title(f'Step {i*5}')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if i == 4:\n",
    "            plt.colorbar(im, ax=ax)\n",
    "    \n",
    "    # Show life pattern analysis\n",
    "    for i, grid in enumerate(grids):\n",
    "        ax = axes[1, i]\n",
    "        # Threshold to show \"alive\" cells\n",
    "        alive_pattern = (grid > coffee.environment_temp + 10).astype(float)\n",
    "        im = ax.imshow(alive_pattern, cmap='RdYlBu_r', interpolation='nearest')\n",
    "        ax.set_title(f'Life Pattern {i*5}')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if i == 4:\n",
    "            plt.colorbar(im, ax=ax)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot life metrics\n",
    "    if life_metrics:\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        \n",
    "        steps = range(len(life_metrics))\n",
    "        \n",
    "        # Extract metrics\n",
    "        oscillator_counts = [m.get('oscillator_count', 0) for m in life_metrics]\n",
    "        still_life_counts = [m.get('still_life_count', 0) for m in life_metrics]\n",
    "        pattern_diversity = [m.get('pattern_diversity', 0) for m in life_metrics]\n",
    "        active_regions = [m.get('active_regions', 0) for m in life_metrics]\n",
    "        \n",
    "        ax1.plot(steps, oscillator_counts, 'b-o', linewidth=2, label='Oscillators')\n",
    "        ax1.set_xlabel('Time Steps')\n",
    "        ax1.set_ylabel('Count')\n",
    "        ax1.set_title('Oscillating Patterns')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        ax2.plot(steps, still_life_counts, 'r-s', linewidth=2, label='Still Life')\n",
    "        ax2.set_xlabel('Time Steps')\n",
    "        ax2.set_ylabel('Count')\n",
    "        ax2.set_title('Stable Patterns')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        ax3.plot(steps, pattern_diversity, 'g-^', linewidth=2, label='Diversity')\n",
    "        ax3.set_xlabel('Time Steps')\n",
    "        ax3.set_ylabel('Diversity Index')\n",
    "        ax3.set_title('Pattern Diversity')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        ax4.plot(steps, active_regions, 'm-d', linewidth=2, label='Active Regions')\n",
    "        ax4.set_xlabel('Time Steps')\n",
    "        ax4.set_ylabel('Count')\n",
    "        ax4.set_title('Active Regions')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"üìà Life Pattern Analysis:\")\n",
    "        print(f\"   Peak Oscillators: {max(oscillator_counts) if oscillator_counts else 0}\")\n",
    "        print(f\"   Stable Patterns: {max(still_life_counts) if still_life_counts else 0}\")\n",
    "        print(f\"   Pattern Diversity: {max(pattern_diversity) if pattern_diversity else 0:.3f}\")\n",
    "\n",
    "# Explore life with optimal parameters\n",
    "explore_coffee_life(optimal_diffusion, optimal_cooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5418a5",
   "metadata": {},
   "source": [
    "## Part 5: Connections to AI and Modern Systems\n",
    "\n",
    "The Coffee Automaton reveals fundamental principles that appear throughout AI and complex systems. Let's explore these connections and understand why complexity theory matters for modern machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dac4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connections to neural networks and AI\n",
    "def demonstrate_ai_connections():\n",
    "    \"\"\"Show connections between coffee automaton and AI systems.\"\"\"\n",
    "    \n",
    "    print(\"üß† Exploring connections to AI and neural networks...\")\n",
    "    \n",
    "    # Create a coffee automaton that mimics neural network dynamics\n",
    "    class NeuralCoffeeAutomaton(CoffeeAutomaton):\n",
    "        \"\"\"Coffee automaton with neural-network-like dynamics.\"\"\"\n",
    "        \n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            # Add \"synaptic weights\" between cells\n",
    "            self.weights = np.random.randn(self.size, self.size, 8) * 0.1\n",
    "            \n",
    "        def step(self):\n",
    "            # Standard coffee dynamics\n",
    "            super().step()\n",
    "            \n",
    "            # Add neural-like activation\n",
    "            activation = np.tanh((self.grid - self.environment_temp) / 10.0)\n",
    "            self.grid = self.environment_temp + activation * 30\n",
    "    \n",
    "    # Compare standard vs neural coffee\n",
    "    coffee_standard = CoffeeAutomaton(size=30, diffusion_rate=0.15, cooling_rate=0.03)\n",
    "    coffee_neural = NeuralCoffeeAutomaton(size=30, diffusion_rate=0.15, cooling_rate=0.03)\n",
    "    \n",
    "    # Add identical initial conditions\n",
    "    coffee_standard.add_hotspot(15, 15, intensity=30, radius=5)\n",
    "    coffee_neural.add_hotspot(15, 15, intensity=30, radius=5)\n",
    "    \n",
    "    # Run both simulations\n",
    "    standard_grids = []\n",
    "    neural_grids = []\n",
    "    \n",
    "    for step in range(30):\n",
    "        if step % 6 == 0:\n",
    "            standard_grids.append(coffee_standard.grid.copy())\n",
    "            neural_grids.append(coffee_neural.grid.copy())\n",
    "        \n",
    "        coffee_standard.step()\n",
    "        coffee_neural.step()\n",
    "    \n",
    "    # Visualize comparison\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(18, 8))\n",
    "    \n",
    "    for i, (std_grid, neural_grid) in enumerate(zip(standard_grids, neural_grids)):\n",
    "        # Standard coffee\n",
    "        im1 = axes[0, i].imshow(std_grid, cmap='hot', vmin=20, vmax=80)\n",
    "        axes[0, i].set_title(f'Standard Step {i*6}')\n",
    "        axes[0, i].set_xticks([])\n",
    "        axes[0, i].set_yticks([])\n",
    "        \n",
    "        # Neural coffee\n",
    "        im2 = axes[1, i].imshow(neural_grid, cmap='hot', vmin=20, vmax=80)\n",
    "        axes[1, i].set_title(f'Neural Step {i*6}')\n",
    "        axes[1, i].set_xticks([])\n",
    "        axes[1, i].set_yticks([])\n",
    "    \n",
    "    axes[0, 0].set_ylabel('Standard Coffee', rotation=90, size=12)\n",
    "    axes[1, 0].set_ylabel('Neural Coffee', rotation=90, size=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze differences\n",
    "    complexity_calc = ComplexityMeasures()\n",
    "    \n",
    "    std_complexity = complexity_calc.calculate_local_complexity(standard_grids[-1]).mean()\n",
    "    neural_complexity = complexity_calc.calculate_local_complexity(neural_grids[-1]).mean()\n",
    "    \n",
    "    std_entropy = complexity_calc.calculate_entropy(standard_grids[-1])\n",
    "    neural_entropy = complexity_calc.calculate_entropy(neural_grids[-1])\n",
    "    \n",
    "    print(f\"üìä Complexity Comparison:\")\n",
    "    print(f\"   Standard Coffee - Complexity: {std_complexity:.3f}, Entropy: {std_entropy:.3f}\")\n",
    "    print(f\"   Neural Coffee   - Complexity: {neural_complexity:.3f}, Entropy: {neural_entropy:.3f}\")\n",
    "    \n",
    "    # Show AI principles demonstrated\n",
    "    print(f\"\\nüéØ AI Principles Demonstrated:\")\n",
    "    print(f\"   üîÑ Emergent Behavior: Complex patterns from simple rules\")\n",
    "    print(f\"   üìä Information Processing: Entropy and complexity dynamics\")\n",
    "    print(f\"   üéöÔ∏è Critical Dynamics: Edge-of-chaos optimal performance\")\n",
    "    print(f\"   üîó Network Effects: Local interactions ‚Üí Global patterns\")\n",
    "    print(f\"   üßÆ Nonlinear Dynamics: Small changes ‚Üí Large effects\")\n",
    "\n",
    "demonstrate_ai_connections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2681a37e",
   "metadata": {},
   "source": [
    "## Part 6: Advanced Analysis and Experiments\n",
    "\n",
    "Let's dive deeper into advanced aspects of the coffee automaton, including phase transitions, criticality, and information flow dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e28018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced analysis: Phase transitions and criticality\n",
    "def analyze_phase_transitions():\n",
    "    \"\"\"Analyze phase transitions in the coffee automaton.\"\"\"\n",
    "    \n",
    "    print(\"üå°Ô∏è Analyzing phase transitions and critical phenomena...\")\n",
    "    \n",
    "    # Explore different noise levels to find phase transitions\n",
    "    noise_levels = np.logspace(-3, -1, 20)  # From 0.001 to 0.1\n",
    "    \n",
    "    order_parameters = []\n",
    "    susceptibilities = []\n",
    "    \n",
    "    for noise in noise_levels:\n",
    "        # Run multiple realizations\n",
    "        order_vals = []\n",
    "        \n",
    "        for realization in range(5):\n",
    "            coffee = CoffeeAutomaton(\n",
    "                size=25,\n",
    "                diffusion_rate=0.12,\n",
    "                cooling_rate=0.025,\n",
    "                noise_level=noise\n",
    "            )\n",
    "            \n",
    "            # Add initial perturbation\n",
    "            coffee.add_hotspot(12, 12, intensity=20, radius=4)\n",
    "            \n",
    "            # Let system evolve\n",
    "            for step in range(40):\n",
    "                coffee.step()\n",
    "            \n",
    "            # Calculate order parameter (temperature variance)\n",
    "            order = np.var(coffee.grid)\n",
    "            order_vals.append(order)\n",
    "        \n",
    "        # Store statistics\n",
    "        mean_order = np.mean(order_vals)\n",
    "        susceptibility = np.var(order_vals)  # Response to noise\n",
    "        \n",
    "        order_parameters.append(mean_order)\n",
    "        susceptibilities.append(susceptibility)\n",
    "    \n",
    "    # Plot phase transition analysis\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Order parameter\n",
    "    ax1.semilogx(noise_levels, order_parameters, 'bo-', linewidth=2, markersize=6)\n",
    "    ax1.set_xlabel('Noise Level')\n",
    "    ax1.set_ylabel('Order Parameter (Temperature Variance)')\n",
    "    ax1.set_title('Order-Disorder Transition')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Susceptibility (critical behavior)\n",
    "    ax2.semilogx(noise_levels, susceptibilities, 'rs-', linewidth=2, markersize=6)\n",
    "    ax2.set_xlabel('Noise Level')\n",
    "    ax2.set_ylabel('Susceptibility')\n",
    "    ax2.set_title('Critical Behavior')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find critical point\n",
    "    max_susceptibility_idx = np.argmax(susceptibilities)\n",
    "    critical_noise = noise_levels[max_susceptibility_idx]\n",
    "    \n",
    "    print(f\"üéØ Critical Point Analysis:\")\n",
    "    print(f\"   Critical noise level: {critical_noise:.4f}\")\n",
    "    print(f\"   Maximum susceptibility: {max(susceptibilities):.3f}\")\n",
    "    print(f\"   This represents the edge-of-chaos transition!\")\n",
    "\n",
    "analyze_phase_transitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650efb2d",
   "metadata": {},
   "source": [
    "## Part 7: Your Turn to Explore!\n",
    "\n",
    "Now it's your turn to experiment with the Coffee Automaton! Try different parameter combinations, initial conditions, or even modify the rules to see what happens.\n",
    "\n",
    "### Suggested Experiments:\n",
    "\n",
    "1. **Boundary Effects**: Try different boundary conditions (periodic vs fixed)\n",
    "2. **Multiple Hotspots**: Add multiple heat sources and watch them interact\n",
    "3. **Custom Rules**: Modify the diffusion or cooling rules\n",
    "4. **Size Effects**: Explore how system size affects complexity\n",
    "5. **Time Scales**: Investigate very long-term behavior\n",
    "\n",
    "Use the cells below to conduct your own experiments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d61100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment cell 1: Your custom experiment here\n",
    "def my_experiment():\n",
    "    \"\"\"Design your own coffee automaton experiment!\"\"\"\n",
    "    \n",
    "    print(\"üî¨ Your Custom Experiment\")\n",
    "    \n",
    "    # TODO: Design your experiment here!\n",
    "    # Ideas:\n",
    "    # - Try extreme parameter values\n",
    "    # - Create custom initial conditions\n",
    "    # - Implement new rules\n",
    "    # - Analyze long-term behavior\n",
    "    \n",
    "    # Example: Multiple interacting hotspots\n",
    "    coffee = CoffeeAutomaton(size=40, diffusion_rate=0.08, cooling_rate=0.02, noise_level=0.005)\n",
    "    \n",
    "    # Add multiple hotspots in a pattern\n",
    "    hotspot_positions = [(10, 10), (30, 30), (10, 30), (30, 10), (20, 20)]\n",
    "    intensities = [25, 20, 15, 30, 35]\n",
    "    \n",
    "    for (x, y), intensity in zip(hotspot_positions, intensities):\n",
    "        coffee.add_hotspot(x, y, intensity=intensity, radius=3)\n",
    "    \n",
    "    # Run and visualize\n",
    "    grids = []\n",
    "    for step in range(60):\n",
    "        if step % 10 == 0:\n",
    "            grids.append(coffee.grid.copy())\n",
    "        coffee.step()\n",
    "    \n",
    "    # Show evolution\n",
    "    fig, axes = plt.subplots(1, len(grids), figsize=(18, 3))\n",
    "    for i, grid in enumerate(grids):\n",
    "        axes[i].imshow(grid, cmap='hot', vmin=20, vmax=60)\n",
    "        axes[i].set_title(f'Step {i*10}')\n",
    "        axes[i].set_xticks([])\n",
    "        axes[i].set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üéâ Experiment complete! What patterns do you observe?\")\n",
    "\n",
    "# Run your experiment\n",
    "my_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeab0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment cell 2: Advanced analysis\n",
    "def advanced_analysis_experiment():\n",
    "    \"\"\"Perform advanced analysis on your coffee automaton.\"\"\"\n",
    "    \n",
    "    print(\"üìà Advanced Analysis Experiment\")\n",
    "    \n",
    "    # Create a coffee automaton with interesting dynamics\n",
    "    coffee = CoffeeAutomaton(size=50, diffusion_rate=0.1, cooling_rate=0.03, noise_level=0.008)\n",
    "    \n",
    "    # Add a spiral pattern as initial condition\n",
    "    center_x, center_y = 25, 25\n",
    "    for angle in np.linspace(0, 4*np.pi, 100):\n",
    "        x = int(center_x + 10 * np.cos(angle) * (1 - angle/(4*np.pi)))\n",
    "        y = int(center_y + 10 * np.sin(angle) * (1 - angle/(4*np.pi)))\n",
    "        if 0 <= x < coffee.size and 0 <= y < coffee.size:\n",
    "            coffee.grid[x, y] = 80\n",
    "    \n",
    "    # Run simulation with detailed tracking\n",
    "    complexity_calc = ComplexityMeasures()\n",
    "    \n",
    "    metrics_history = {\n",
    "        'complexity': [],\n",
    "        'entropy': [],\n",
    "        'temperature': [],\n",
    "        'spatial_correlation': []\n",
    "    }\n",
    "    \n",
    "    for step in range(100):\n",
    "        # Calculate various metrics\n",
    "        complexity = complexity_calc.calculate_local_complexity(coffee.grid)\n",
    "        entropy = complexity_calc.calculate_entropy(coffee.grid)\n",
    "        \n",
    "        # Spatial correlation (how correlated are neighboring cells?)\n",
    "        shifted = np.roll(coffee.grid, 1, axis=0)\n",
    "        correlation = np.corrcoef(coffee.grid.flatten(), shifted.flatten())[0,1]\n",
    "        \n",
    "        metrics_history['complexity'].append(complexity.mean())\n",
    "        metrics_history['entropy'].append(entropy)\n",
    "        metrics_history['temperature'].append(coffee.grid.mean())\n",
    "        metrics_history['spatial_correlation'].append(correlation)\n",
    "        \n",
    "        coffee.step()\n",
    "    \n",
    "    # Plot comprehensive analysis\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    time_steps = range(len(metrics_history['complexity']))\n",
    "    \n",
    "    ax1.plot(time_steps, metrics_history['complexity'], 'b-', linewidth=2, label='Complexity')\n",
    "    ax1.set_xlabel('Time Steps')\n",
    "    ax1.set_ylabel('Local Complexity')\n",
    "    ax1.set_title('Complexity Evolution')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2.plot(time_steps, metrics_history['entropy'], 'r-', linewidth=2, label='Entropy')\n",
    "    ax2.set_xlabel('Time Steps')\n",
    "    ax2.set_ylabel('System Entropy')\n",
    "    ax2.set_title('Information Dynamics')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax3.plot(time_steps, metrics_history['temperature'], 'orange', linewidth=2, label='Temperature')\n",
    "    ax3.set_xlabel('Time Steps')\n",
    "    ax3.set_ylabel('Average Temperature')\n",
    "    ax3.set_title('Thermal Evolution')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax4.plot(time_steps, metrics_history['spatial_correlation'], 'purple', linewidth=2, label='Correlation')\n",
    "    ax4.set_xlabel('Time Steps')\n",
    "    ax4.set_ylabel('Spatial Correlation')\n",
    "    ax4.set_title('Spatial Structure')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìä Analysis Results:\")\n",
    "    print(f\"   Peak complexity: {max(metrics_history['complexity']):.3f}\")\n",
    "    print(f\"   Final entropy: {metrics_history['entropy'][-1]:.3f}\")\n",
    "    print(f\"   Temperature drop: {metrics_history['temperature'][0] - metrics_history['temperature'][-1]:.2f}¬∞C\")\n",
    "    print(f\"   Final correlation: {metrics_history['spatial_correlation'][-1]:.3f}\")\n",
    "\n",
    "# Run advanced analysis\n",
    "advanced_analysis_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078dbf3e",
   "metadata": {},
   "source": [
    "## Conclusions and Takeaways\n",
    "\n",
    "üéâ **Congratulations!** You've completed an in-depth exploration of complexity dynamics through the Coffee Automaton model.\n",
    "\n",
    "### Key Insights Discovered:\n",
    "\n",
    "1. **Emergence**: Complex behaviors arise from simple local rules\n",
    "2. **Sweet Spots**: Optimal complexity occurs at specific parameter regimes\n",
    "3. **Phase Transitions**: Systems exhibit critical behavior at transition points\n",
    "4. **Information Flow**: Entropy and complexity provide insights into system dynamics\n",
    "5. **Life-like Patterns**: Self-organizing structures emerge naturally\n",
    "6. **AI Connections**: Same principles apply to neural networks and machine learning\n",
    "\n",
    "### Why This Matters for AI:\n",
    "\n",
    "- **Neural Network Design**: Understanding how complexity emerges helps design better architectures\n",
    "- **Optimization Landscapes**: Critical dynamics inform training strategies\n",
    "- **Emergent Behavior**: Insight into how AI systems develop unexpected capabilities\n",
    "- **Information Processing**: Entropy principles guide efficient computation\n",
    "- **Self-Organization**: Understanding how structure emerges without explicit programming\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Experiment Further**: Try your own parameter combinations and initial conditions\n",
    "2. **Connect to Research**: Read papers on complexity theory and neural networks\n",
    "3. **Implement Variations**: Create your own cellular automata models\n",
    "4. **Apply Insights**: Use complexity principles in your own AI projects\n",
    "\n",
    "The journey from a simple coffee cup to understanding fundamental principles of intelligence shows how powerful simple models can be for gaining deep insights!\n",
    "\n",
    "Keep exploring, keep questioning, and remember - complexity is everywhere! ‚òïüß†‚ú®"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
