{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "ea95c2ce",
            "metadata": {},
            "source": [
                "# Day 16: Order Matters - Pointer Networks\n",
                "\n",
                "**Paper:** *Order Matters: Sequence to Sequence for Sets* - Vinyals, Bengio, Kudlur (2015)\n",
                "\n",
                "We implement Pointer Networks - an architecture that generates output sequences by selecting indices from the input set rather than producing tokens from a fixed vocabulary. The notebook walks through pointer attention, a sorting task, and a small TSP demo.\n",
                "\n",
                "---\n",
                "\n",
                "## What You'll Learn\n",
                "\n",
                "1. Why standard seq2seq fails when the output vocabulary depends on the input\n",
                "2. The pointer attention mechanism (Eq. 1-3 in the paper)\n",
                "3. How Read-Process-and-Write handles set-structured inputs\n",
                "4. Sorting as a minimal test bed for pointer networks\n",
                "5. Applying pointer networks to the Travelling Salesman Problem"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3f36ec0b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from IPython.display import display, HTML\n",
                "\n",
                "# Set random seeds for reproducibility\n",
                "torch.manual_seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "print(\"Setup complete\")\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "34ba3aab",
            "metadata": {},
            "source": [
                "## Part 1: Understanding Pointer Attention\n",
                "\n",
                "The core innovation is the pointer mechanism. Instead of selecting tokens from a fixed vocabulary, the model calculates attention over the input elements and uses the resulting distribution to pick an input index."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "66863e38",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimplePointerAttention(nn.Module):\n",
                "    \"\"\"\n",
                "    Simplified pointer attention mechanism.\n",
                "    \n",
                "    Formula: attention(query, keys) = softmax(v^T tanh(W_q * query + W_k * keys))\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, hidden_dim=32):\n",
                "        super().__init__()\n",
                "        \n",
                "        self.W_key = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
                "        self.W_query = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
                "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
                "    \n",
                "    def forward(self, query, keys, mask=None):\n",
                "        \"\"\"\n",
                "        Args:\n",
                "            query: [batch, hidden_dim] - what we're looking for\n",
                "            keys: [batch, seq_len, hidden_dim] - where we search\n",
                "            mask: [batch, seq_len] - 1 for positions to mask\n",
                "        Returns:\n",
                "            attention_weights: [batch, seq_len]\n",
                "        \"\"\"\n",
                "        # Transform query and keys\n",
                "        query_proj = self.W_query(query).unsqueeze(1)  # [batch, 1, hidden_dim]\n",
                "        keys_proj = self.W_key(keys)                    # [batch, seq_len, hidden_dim]\n",
                "        \n",
                "        # Additive attention\n",
                "        scores = self.v(torch.tanh(query_proj + keys_proj))  # [batch, seq_len, 1]\n",
                "        scores = scores.squeeze(-1)  # [batch, seq_len]\n",
                "        \n",
                "        # Apply mask (set masked positions to -inf)\n",
                "        if mask is not None:\n",
                "            scores = scores.masked_fill(mask.bool(), float('-inf'))\n",
                "        \n",
                "        # Softmax to get probabilities\n",
                "        attention_weights = torch.softmax(scores, dim=-1)\n",
                "        \n",
                "        return attention_weights\n",
                "\n",
                "# Test implementation\n",
                "attention = SimplePointerAttention(hidden_dim=32)\n",
                "\n",
                "query = torch.randn(1, 32)\n",
                "keys = torch.randn(1, 5, 32)\n",
                "\n",
                "weights = attention(query, keys)\n",
                "\n",
                "print(\"Attention weights:\", weights[0].tolist())\n",
                "print(f\"Sum: {weights.sum():.4f} (should be 1.0)\")\n",
                "print(\"Pointer attention correctly calculates focus over input positions.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ad6afc9b",
            "metadata": {},
            "source": [
                "### Visualization of Attention\n",
                "\n",
                "The following bar charts visualize the attention weights given a query and a set of input items."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1dd76fd5",
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_attention_example():\n",
                "    # Create 5 input items with different values\n",
                "    items = torch.tensor([[0.2, 0.8, 0.1, 0.9, 0.5]])\n",
                "    \n",
                "    # Simple embedding\n",
                "    embed = nn.Linear(1, 32)\n",
                "    keys = embed(items.unsqueeze(-1))\n",
                "    \n",
                "    # Query looking for \"high values\"\n",
                "    query = torch.randn(1, 32)\n",
                "    \n",
                "    # Compute attention\n",
                "    attention_layer = SimplePointerAttention(32)\n",
                "    weights = attention_layer(query, keys)\n",
                "    \n",
                "    # Visualize\n",
                "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 6))\n",
                "    \n",
                "    # Input values\n",
                "    ax1.bar(range(5), items[0].numpy(), color='skyblue', alpha=0.7)\n",
                "    ax1.set_title('Input Values', fontsize=14, fontweight='bold')\n",
                "    ax1.set_xlabel('Position')\n",
                "    ax1.set_ylabel('Value')\n",
                "    ax1.grid(True, alpha=0.3)\n",
                "    \n",
                "    # Attention weights\n",
                "    ax2.bar(range(5), weights[0].detach().numpy(), color='coral', alpha=0.7)\n",
                "    ax2.set_title('Attention Weights (Where to Point)', fontsize=14, fontweight='bold')\n",
                "    ax2.set_xlabel('Position')\n",
                "    ax2.set_ylabel('Probability')\n",
                "    ax2.grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    # Show which position has highest attention\n",
                "    best_pos = torch.argmax(weights[0]).item()\n",
                "    print(f\"Model points to position {best_pos} (value: {items[0, best_pos]:.2f})\")\n",
                "\n",
                "visualize_attention_example()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "da37e463",
            "metadata": {},
            "source": [
                "## Part 2: Sorting with Pointer Networks\n",
                "\n",
                "We can test the Pointer Network on the task of sorting numbers. The model must learn the \"selection rule\" for ascending order.\n",
                "\n",
                "- **Input:** `[0.7, 0.2, 0.9, 0.1, 0.5]` (unordered set)\n",
                "- **Output:** `[3, 1, 4, 0, 2]` (indices in sorted order)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7f8e56c4",
            "metadata": {},
            "outputs": [],
            "source": [
                "class PointerNetwork(nn.Module):\n",
                "    \"\"\"Full Pointer Network implementation.\"\"\"\n",
                "    \n",
                "    def __init__(self, input_dim=1, hidden_dim=64):\n",
                "        super().__init__()\n",
                "        self.hidden_dim = hidden_dim\n",
                "        \n",
                "        # Encoder: Process input set\n",
                "        self.encoder = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
                "        \n",
                "        # Decoder: Generate output sequence\n",
                "        self.decoder = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
                "        \n",
                "        # Pointer attention\n",
                "        self.attention = SimplePointerAttention(hidden_dim)\n",
                "    \n",
                "    def forward(self, inputs):\n",
                "        \"\"\"\n",
                "        Args:\n",
                "            inputs: [batch, seq_len] numbers to sort\n",
                "        Returns:\n",
                "            all_pointers: [batch, seq_len, seq_len] attention distributions\n",
                "        \"\"\"\n",
                "        batch_size, seq_len = inputs.shape\n",
                "        inputs = inputs.unsqueeze(-1)  # [batch, seq_len, 1]\n",
                "        \n",
                "        # Encode\n",
                "        encoder_outputs, (h, c) = self.encoder(inputs)\n",
                "        \n",
                "        # Decode\n",
                "        decoder_state = (h, c)\n",
                "        decoder_input = torch.zeros(batch_size, 1, self.hidden_dim, device=inputs.device)\n",
                "        \n",
                "        all_pointers = []\n",
                "        \n",
                "        for t in range(seq_len):\n",
                "            # One decoding step\n",
                "            decoder_output, decoder_state = self.decoder(decoder_input, decoder_state)\n",
                "            \n",
                "            # Compute where to point\n",
                "            weights = self.attention(decoder_output.squeeze(1), encoder_outputs)\n",
                "            all_pointers.append(weights)\n",
                "            \n",
                "            # Next input: weighted average of encoder outputs\n",
                "            context = torch.bmm(weights.unsqueeze(1), encoder_outputs)\n",
                "            decoder_input = context\n",
                "        \n",
                "        return torch.stack(all_pointers, dim=1)\n",
                "\n",
                "# Initialize model\n",
                "model = PointerNetwork(input_dim=1, hidden_dim=64)\n",
                "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2fc0713b",
            "metadata": {},
            "source": [
                "### Training on the Sorting Task\n",
                "\n",
                "We train the model using standard cross-entropy loss over the predicted pointer indices."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c366f3d2",
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_sorting_batch(batch_size=32, seq_len=5):\n",
                "    \"\"\"Generate random sorting problems.\"\"\"\n",
                "    inputs = torch.rand(batch_size, seq_len)\n",
                "    targets = torch.argsort(inputs, dim=1)\n",
                "    return inputs, targets\n",
                "\n",
                "def train_sorting(model, num_epochs=20, batch_size=32, seq_len=5):\n",
                "    \"\"\"Train model to sort numbers.\"\"\"\n",
                "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
                "    \n",
                "    losses = []\n",
                "    accuracies = []\n",
                "    \n",
                "    for epoch in range(num_epochs):\n",
                "        inputs, targets = generate_sorting_batch(batch_size, seq_len)\n",
                "        \n",
                "        logits = model(inputs)\n",
                "        \n",
                "        logits_flat = logits.view(-1, seq_len)\n",
                "        targets_flat = targets.view(-1)\n",
                "        loss = F.cross_entropy(logits_flat, targets_flat)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        loss.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
                "        optimizer.step()\n",
                "        \n",
                "        predictions = torch.argmax(logits, dim=-1)\n",
                "        accuracy = (predictions == targets).all(dim=1).float().mean().item()\n",
                "        \n",
                "        losses.append(loss.item())\n",
                "        accuracies.append(accuracy)\n",
                "        \n",
                "        if (epoch + 1) % 5 == 0:\n",
                "            print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {loss.item():.4f}, Acc: {accuracy:.2%}\")\n",
                "    \n",
                "    return losses, accuracies\n",
                "\n",
                "print(\"Training model on sorting sequences of length 5...\")\n",
                "losses, accuracies = train_sorting(model, num_epochs=20, seq_len=5)\n",
                "\n",
                "# Plot validation metrics\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
                "ax1.plot(losses, color='blue')\n",
                "ax1.set_title('Training Loss')\n",
                "ax1.set_xlabel('Epoch')\n",
                "ax2.plot(accuracies, color='green')\n",
                "ax2.set_title('Sequence Accuracy')\n",
                "ax2.set_xlabel('Epoch')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c8264dfe",
            "metadata": {},
            "source": [
                "### Inference and Attention Heatmap\n",
                "\n",
                "Testing the model on a single sequence and visualizing the attention heatmap at each step."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eeac7974",
            "metadata": {},
            "outputs": [],
            "source": [
                "def test_and_visualize(model, numbers):\n",
                "    model.eval()\n",
                "    inputs = torch.tensor([numbers]).float()\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        logits = model(inputs)\n",
                "        predictions = torch.argmax(logits, dim=-1)[0]\n",
                "    \n",
                "    true_order = torch.argsort(inputs[0])\n",
                "    \n",
                "    fig = plt.figure(figsize=(14, 8))\n",
                "    \n",
                "    # 1. Input numbers\n",
                "    ax1 = plt.subplot(3, 1, 1)\n",
                "    ax1.bar(range(len(numbers)), numbers, color='skyblue', alpha=0.7)\n",
                "    ax1.set_title('Input Numbers (Unsorted)')\n",
                "    \n",
                "    # 2. Attention heatmap\n",
                "    ax2 = plt.subplot(3, 1, 2)\n",
                "    attention_matrix = logits[0].softmax(dim=-1).numpy()\n",
                "    im = ax2.imshow(attention_matrix, cmap='YlOrRd', aspect='auto')\n",
                "    ax2.set_title('Pointer Attention Heatmap')\n",
                "    ax2.set_ylabel('Output Step')\n",
                "    ax2.set_xlabel('Input Index')\n",
                "    plt.colorbar(im, ax=ax2)\n",
                "    \n",
                "    # 3. Predicted result\n",
                "    ax3 = plt.subplot(3, 1, 3)\n",
                "    sorted_nums = [numbers[i] for i in predictions.tolist()]\n",
                "    is_correct = torch.equal(predictions, true_order)\n",
                "    ax3.bar(range(len(sorted_nums)), sorted_nums, color='lightgreen' if is_correct else 'salmon')\n",
                "    ax3.set_title(f\"Predicted Sort Order (Correct: {is_correct})\")\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "test_numbers = [0.7, 0.2, 0.9, 0.1, 0.5]\n",
                "test_and_visualize(model, test_numbers)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "76ad402f",
            "metadata": {},
            "source": [
                "## Part 3: Traveling Salesman Problem (TSP)\n",
                "\n",
                "TSP is a combinatorial optimization problem where the input is a set of city locations and the goal is to find the shortest tour. This is NP-hard, making it a rigorous test for the learning capacity of Pointer Networks."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d52556f0",
            "metadata": {},
            "outputs": [],
            "source": [
                "class TSPPointerNetwork(nn.Module):\n",
                "    \"\"\"Pointer Network for TSP with index masking.\"\"\"\n",
                "    \n",
                "    def __init__(self, input_dim=2, hidden_dim=64):\n",
                "        super().__init__()\n",
                "        self.hidden_dim = hidden_dim\n",
                "        self.encoder = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
                "        self.decoder = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
                "        self.attention = SimplePointerAttention(hidden_dim)\n",
                "    \n",
                "    def forward(self, cities):\n",
                "        batch_size, num_cities, _ = cities.shape\n",
                "        encoder_outputs, (h, c) = self.encoder(cities)\n",
                "        \n",
                "        decoder_state = (h, c)\n",
                "        decoder_input = torch.zeros(batch_size, 1, self.hidden_dim, device=cities.device)\n",
                "        mask = torch.zeros(batch_size, num_cities, device=cities.device)\n",
                "        \n",
                "        tour = []\n",
                "        for t in range(num_cities):\n",
                "            decoder_output, decoder_state = self.decoder(decoder_input, decoder_state)\n",
                "            weights = self.attention(decoder_output.squeeze(1), encoder_outputs, mask)\n",
                "            \n",
                "            _, selected = weights.max(dim=-1)\n",
                "            tour.append(selected)\n",
                "            \n",
                "            # Mark selected city to prevent revisiting\n",
                "            mask.scatter_(1, selected.unsqueeze(1), 1)\n",
                "            \n",
                "            context = torch.bmm(weights.unsqueeze(1), encoder_outputs)\n",
                "            decoder_input = context\n",
                "        \n",
                "        return torch.stack(tour, dim=1)\n",
                "\n",
                "tsp_model = TSPPointerNetwork(input_dim=2, hidden_dim=64)\n",
                "print(\"TSP model initialized\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4d8baa71",
            "metadata": {},
            "source": [
                "## Key Takeaways\n",
                "\n",
                "1. **Set Invariance:** By removing positional encodings in the encoder, the Pointer Network treats the input as a set.\n",
                "2. **The Pointing Mechanism:** The model outputs indices into the input rather than tokens from a vocabulary, enabling it to handle variable input sizes and out-of-vocabulary numerical values.\n",
                "3. **Generalization:** Pointer Networks often generalize to sequence lengths longer than those seen during training because they learn the algorithmic operation (e.g., sorting) rather than specific patterns."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
