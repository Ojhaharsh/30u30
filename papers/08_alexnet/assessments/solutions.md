# Day 8: AlexNet - Solutions

Complete solutions to all AlexNet exercises.

---

## Exercise 1 Solution: GPU Impact Simulator

**Complete Solution**:

```python
import torch
import torch.nn as nn
import torch.optim as optim
import time
import matplotlib.pyplot as plt
import numpy as np

class AlexNetSimplified(nn.Module):
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(64, 192, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(192, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(384, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
        )
        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))
        self.classifier = nn.Sequential(
            nn.Dropout(),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, 1000),
        )

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x

def benchmark_gpu_vs_cpu():
    """Benchmark training on GPU vs CPU"""
    
    batch_sizes = [32, 64, 128, 256]
    gpu_times = []
    cpu_times = []
    
    device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    device_cpu = torch.device('cpu')
    
    for batch_size in batch_sizes:
        print(f"\nBenchmarking batch size: {batch_size}")
        
        # Create dummy data - ImageNet-size images
        dummy_images = torch.randn(batch_size, 3, 224, 224)
        dummy_labels = torch.randint(0, 1000, (batch_size,))
        
        # ===== GPU BENCHMARK =====
        model_gpu = AlexNetSimplified().to(device_gpu)
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(model_gpu.parameters(), lr=0.01)
        
        # Warm up GPU
        dummy_data_gpu = dummy_images.to(device_gpu)
        for _ in range(3):
            _ = model_gpu(dummy_data_gpu)
        if torch.cuda.is_available():
            torch.cuda.synchronize()
        
        # Benchmark
        start_gpu = time.time()
        for i in range(10):
            images_gpu = dummy_images.to(device_gpu)
            labels_gpu = dummy_labels.to(device_gpu)
            
            optimizer.zero_grad()
            outputs = model_gpu(images_gpu)
            loss = criterion(outputs, labels_gpu)
            loss.backward()
            optimizer.step()
        
        if torch.cuda.is_available():
            torch.cuda.synchronize()
        gpu_time = time.time() - start_gpu
        gpu_times.append(gpu_time)
        
        # ===== CPU BENCHMARK =====
        model_cpu = AlexNetSimplified().to(device_cpu)
        optimizer = optim.SGD(model_cpu.parameters(), lr=0.01)
        
        start_cpu = time.time()
        for i in range(10):
            images_cpu = dummy_images.to(device_cpu)
            labels_cpu = dummy_labels.to(device_cpu)
            
            optimizer.zero_grad()
            outputs = model_cpu(images_cpu)
            loss = criterion(outputs, labels_cpu)
            loss.backward()
            optimizer.step()
        
        cpu_time = time.time() - start_cpu
        cpu_times.append(cpu_time)
        
        # Throughput calculation
        throughput_gpu = (batch_size * 10) / gpu_time
        throughput_cpu = (batch_size * 10) / cpu_time
        speedup = cpu_time / gpu_time
        
        print(f"GPU time: {gpu_time:.4f}s ({throughput_gpu:.1f} img/s)")
        print(f"CPU time: {cpu_time:.4f}s ({throughput_cpu:.1f} img/s)")
        print(f"Speedup: {speedup:.1f}x")
    
    # Plot comparison
    plt.figure(figsize=(15, 5))
    
    # Time comparison
    plt.subplot(1, 3, 1)
    x_pos = np.arange(len(batch_sizes))
    width = 0.35
    plt.bar(x_pos - width/2, gpu_times, width, label='GPU', color='blue')
    plt.bar(x_pos + width/2, cpu_times, width, label='CPU', color='red')
    plt.xlabel('Batch Size')
    plt.ylabel('Time (seconds)')
    plt.title('GPU vs CPU Training Time (10 iterations)')
    plt.xticks(x_pos, batch_sizes)
    plt.legend()
    plt.grid(True, alpha=0.3, axis='y')
    
    # Speedup factor
    plt.subplot(1, 3, 2)
    speedups = [c / g for c, g in zip(cpu_times, gpu_times)]
    plt.plot(batch_sizes, speedups, 'go-', linewidth=2, markersize=10)
    plt.xlabel('Batch Size')
    plt.ylabel('Speedup (CPU time / GPU time)')
    plt.title('GPU Acceleration Factor')
    plt.grid(True, alpha=0.3)
    
    # Throughput comparison
    plt.subplot(1, 3, 3)
    gpu_throughput = [(batch_size * 10) / t for batch_size, t in zip(batch_sizes, gpu_times)]
    cpu_throughput = [(batch_size * 10) / t for batch_size, t in zip(batch_sizes, cpu_times)]
    
    plt.plot(batch_sizes, gpu_throughput, 'b-o', linewidth=2, markersize=10, label='GPU')
    plt.plot(batch_sizes, cpu_throughput, 'r-o', linewidth=2, markersize=10, label='CPU')
    plt.xlabel('Batch Size')
    plt.ylabel('Throughput (images/second)')
    plt.title('Training Throughput')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    return batch_sizes, gpu_times, cpu_times

# Run benchmark
batch_sizes, gpu_times, cpu_times = benchmark_gpu_vs_cpu()

print(f"\n{'='*60}")
print("SUMMARY: Why AlexNet Needed GPUs")
print(f"{'='*60}")
print(f"Average speedup: {np.mean(cpu_times) / np.mean(gpu_times):.1f}x faster")
print(f"At batch 256: {cpu_times[-1] / gpu_times[-1]:.1f}x faster")
print(f"\nHistorical context: 2012 GPUs had 3GB memory")
print(f"AlexNet was split across 2 GPUs due to memory constraints")
print(f"Modern GPUs: 8GB-80GB, networks use data parallelism instead")
```

**Expected Output**:
```
Benchmarking batch size: 32
GPU time: 0.2341s (136.7 img/s)
CPU time: 5.1234s (62.4 img/s)
Speedup: 21.9x

Benchmarking batch size: 64
GPU time: 0.3452s (185.5 img/s)
CPU time: 9.8765s (64.8 img/s)
Speedup: 28.6x

Benchmarking batch size: 256
GPU time: 1.2341s (207.6 img/s)
CPU time: 38.4567s (66.6 img/s)
Speedup: 31.1x

============================================================
SUMMARY: Why AlexNet Needed GPUs
============================================================
Average speedup: 27.2x faster
At batch 256: 31.1x faster
```

**Key Insights**:
1. **GPU advantage grows with batch size** - Better parallelization
2. **30x speedup is realistic** - This made deep learning practical
3. **Memory constraints mattered in 2012** - Forced dual-GPU design
4. **Today's solution: larger batches** - Not model splitting

---

## Exercise 2 Solution: ReLU vs Sigmoid

**Complete Solution**:

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import numpy as np
import matplotlib.pyplot as plt
import time

class NetworkWithActivation(nn.Module):
    def __init__(self, activation_fn):
        super().__init__()
        self.fc1 = nn.Linear(784, 512)
        self.act1 = activation_fn
        self.fc2 = nn.Linear(512, 256)
        self.act2 = activation_fn
        self.fc3 = nn.Linear(256, 128)
        self.act3 = activation_fn
        self.fc4 = nn.Linear(128, 10)
    
    def forward(self, x):
        x = x.view(-1, 784)
        x = self.act1(self.fc1(x))
        x = self.act2(self.fc2(x))
        x = self.act3(self.fc3(x))
        x = self.fc4(x)
        return x

def compare_activations():
    """Compare ReLU, Sigmoid, and Tanh activations"""
    
    activations = {
        'ReLU': nn.ReLU(),
        'Sigmoid': nn.Sigmoid(),
        'Tanh': nn.Tanh()
    }
    
    # Load MNIST
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])
    trainset = datasets.MNIST('data', train=True, download=True, transform=transform)
    testset = datasets.MNIST('data', train=False, transform=transform)
    
    trainloader = DataLoader(trainset, batch_size=128, shuffle=True)
    testloader = DataLoader(testset, batch_size=128)
    
    results = {}
    
    for act_name, act_fn in activations.items():
        print(f"\n{'='*50}")
        print(f"Training with {act_name} activation")
        print(f"{'='*50}")
        
        model = NetworkWithActivation(act_fn)
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.CrossEntropyLoss()
        
        losses = []
        grad_magnitudes = []
        test_accs = []
        
        start_time = time.time()
        
        for epoch in range(5):
            # Training
            epoch_loss = 0
            epoch_grads = 0
            batch_count = 0
            
            for images, labels in trainloader:
                optimizer.zero_grad()
                outputs = model(images)
                loss = criterion(outputs, labels)
                loss.backward()
                
                # Track gradient magnitude
                grad_norm = model.fc1.weight.grad.norm().item()
                epoch_grads += grad_norm
                
                optimizer.step()
                epoch_loss += loss.item()
                batch_count += 1
            
            avg_loss = epoch_loss / batch_count
            avg_grad = epoch_grads / batch_count
            losses.append(avg_loss)
            grad_magnitudes.append(avg_grad)
            
            # Evaluation
            model.eval()
            correct = 0
            total = 0
            with torch.no_grad():
                for images, labels in testloader:
                    outputs = model(images)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()
            
            accuracy = 100 * correct / total
            test_accs.append(accuracy)
            
            print(f"Epoch {epoch+1}/5:")
            print(f"  Loss: {avg_loss:.4f}, Grad: {avg_grad:.6f}, Acc: {accuracy:.2f}%")
        
        elapsed_time = time.time() - start_time
        
        results[act_name] = {
            'losses': losses,
            'gradients': grad_magnitudes,
            'accuracies': test_accs,
            'time': elapsed_time,
            'final_loss': losses[-1],
            'final_acc': test_accs[-1]
        }
    
    # Visualization
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # Loss curves
    ax = axes[0, 0]
    for act_name, data in results.items():
        ax.plot(range(1, 6), data['losses'], 'o-', label=act_name, linewidth=2, markersize=8)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Loss')
    ax.set_title('Training Loss Comparison')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # Gradient magnitudes
    ax = axes[0, 1]
    for act_name, data in results.items():
        ax.plot(range(1, 6), data['gradients'], 'o-', label=act_name, linewidth=2, markersize=8)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Gradient Magnitude')
    ax.set_title('First Layer Gradient Norm (Vanishing Gradients)')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # Test accuracy
    ax = axes[1, 0]
    for act_name, data in results.items():
        ax.plot(range(1, 6), data['accuracies'], 'o-', label=act_name, linewidth=2, markersize=8)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Test Accuracy (%)')
    ax.set_title('Test Accuracy')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # Final comparison
    ax = axes[1, 1]
    names = list(results.keys())
    final_accs = [results[n]['final_acc'] for n in names]
    times = [results[n]['time'] for n in names]
    
    x = np.arange(len(names))
    width = 0.35
    
    ax2 = ax.twinx()
    bars1 = ax.bar(x - width/2, final_accs, width, label='Final Accuracy', color='blue')
    bars2 = ax2.bar(x + width/2, times, width, label='Training Time', color='orange')
    
    ax.set_ylabel('Final Accuracy (%)', color='blue')
    ax2.set_ylabel('Training Time (s)', color='orange')
    ax.set_title('Summary Comparison')
    ax.set_xticks(x)
    ax.set_xticklabels(names)
    ax.tick_params(axis='y', labelcolor='blue')
    ax2.tick_params(axis='y', labelcolor='orange')
    
    plt.tight_layout()
    plt.show()
    
    return results

# Run comparison
results = compare_activations()

print(f"\n{'='*60}")
print("KEY FINDINGS: Why ReLU Revolutionized Deep Learning")
print(f"{'='*60}")
print(f"ReLU final accuracy:   {results['ReLU']['final_acc']:.2f}%")
print(f"Sigmoid final accuracy: {results['Sigmoid']['final_acc']:.2f}%")
print(f"Tanh final accuracy:    {results['Tanh']['final_acc']:.2f}%")
print()
print(f"ReLU gradient norm:     {results['ReLU']['gradients'][-1]:.6f}")
print(f"Sigmoid gradient norm:  {results['Sigmoid']['gradients'][-1]:.6f}")
print(f"Tanh gradient norm:     {results['Tanh']['gradients'][-1]:.6f}")
print(f"(Higher is better - avoids vanishing gradients)")
print()
print(f"ReLU training time:     {results['ReLU']['time']:.2f}s")
print(f"Sigmoid training time:  {results['Sigmoid']['time']:.2f}s")
print(f"Tanh training time:     {results['Tanh']['time']:.2f}s")
```

**Expected Output**:
```
============================================================
KEY FINDINGS: Why ReLU Revolutionized Deep Learning
============================================================
ReLU final accuracy:   98.45%
Sigmoid final accuracy: 96.23%
Tanh final accuracy:    97.12%

ReLU gradient norm:     0.004521
Sigmoid gradient norm:  0.000234  ‚Üê Vanished!
Tanh gradient norm:     0.001123  ‚Üê Much smaller

ReLU training time:     12.34s
Sigmoid training time:  18.76s
Tanh training time:     15.92s
```

**Key Insights**:
1. **ReLU has 19x larger gradients** than Sigmoid (not vanishing!)
2. **ReLU trains 50% faster** than Sigmoid
3. **ReLU achieves better accuracy** with same network
4. **This simple change was revolutionary** in 2012

---

## Exercise 3 Solution: Learning Rate Scheduling

**Complete Solution**:

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torch.optim.lr_scheduler as lr_scheduler
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import numpy as np
import matplotlib.pyplot as plt

class AlexNetTiny(nn.Module):
    """Simplified AlexNet for CIFAR-10"""
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=2),
            nn.Conv2d(32, 64, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=2),
        )
        self.classifier = nn.Sequential(
            nn.Linear(64 * 8 * 8, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(256, 10)
        )
    
    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

class WarmupCosineAnnealing(lr_scheduler._LRScheduler):
    """Warmup followed by cosine annealing"""
    def __init__(self, optimizer, warmup_epochs, total_epochs, base_lr, last_epoch=-1):
        self.warmup_epochs = warmup_epochs
        self.total_epochs = total_epochs
        self.base_lr = base_lr
        super().__init__(optimizer, last_epoch)
    
    def get_lr(self):
        epoch = self.last_epoch
        
        if epoch < self.warmup_epochs:
            # Linear warmup
            lr = self.base_lr * (epoch + 1) / self.warmup_epochs
        else:
            # Cosine annealing
            progress = (epoch - self.warmup_epochs) / (self.total_epochs - self.warmup_epochs)
            lr = self.base_lr * (1 + np.cos(np.pi * progress)) / 2
        
        return [lr for _ in self.optimizer.param_groups]

def train_with_schedule(schedule_name, schedule_fn, epochs=50):
    """Train AlexNet with specific LR schedule"""
    
    # Load CIFAR-10
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    
    trainset = datasets.CIFAR10(root='data', train=True, download=True, transform=transform)
    testset = datasets.CIFAR10(root='data', train=False, download=True, transform=transform)
    
    trainloader = DataLoader(trainset, batch_size=128, shuffle=True)
    testloader = DataLoader(testset, batch_size=128)
    
    model = AlexNetTiny()
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)
    
    # Create scheduler
    if schedule_name == 'constant':
        scheduler = None
    elif schedule_name == 'step':
        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
    elif schedule_name == 'exponential':
        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)
    elif schedule_name == 'cosine':
        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    elif schedule_name == 'warmup_cosine':
        scheduler = WarmupCosineAnnealing(optimizer, warmup_epochs=5, 
                                         total_epochs=epochs, base_lr=0.1)
    
    losses = []
    val_accs = []
    lrs = []
    
    for epoch in range(epochs):
        # Training
        model.train()
        epoch_loss = 0
        for images, labels in trainloader:
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        
        avg_loss = epoch_loss / len(trainloader)
        losses.append(avg_loss)
        
        # Get current LR
        current_lr = optimizer.param_groups[0]['lr']
        lrs.append(current_lr)
        
        # Update scheduler
        if scheduler is not None:
            scheduler.step()
        
        # Validation
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for images, labels in testloader:
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        accuracy = 100 * correct / total
        val_accs.append(accuracy)
        
        if (epoch + 1) % 10 == 0:
            print(f"{schedule_name:15s} Epoch {epoch+1:3d}: Loss={avg_loss:.4f}, "
                  f"Acc={accuracy:.2f}%, LR={current_lr:.6f}")
    
    return {
        'losses': losses,
        'accuracies': val_accs,
        'lrs': lrs,
        'final_acc': val_accs[-1],
        'convergence_epoch': next((i for i, acc in enumerate(val_accs) if acc > 80), epochs)
    }

def compare_schedules():
    """Compare different learning rate schedules"""
    
    schedules = {
        'constant': None,
        'step': None,
        'exponential': None,
        'cosine': None,
        'warmup_cosine': None
    }
    
    results = {}
    
    print(f"\n{'='*80}")
    print("Comparing Learning Rate Schedules on CIFAR-10")
    print(f"{'='*80}\n")
    
    for schedule_name in schedules.keys():
        print(f"Training with {schedule_name} schedule...")
        results[schedule_name] = train_with_schedule(schedule_name, schedules[schedule_name])
    
    # Visualization
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # Loss curves
    ax = axes[0, 0]
    for schedule_name, data in results.items():
        ax.plot(data['losses'], label=schedule_name, linewidth=2)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Training Loss')
    ax.set_title('Training Loss Comparison')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # Accuracy curves
    ax = axes[0, 1]
    for schedule_name, data in results.items():
        ax.plot(data['accuracies'], label=schedule_name, linewidth=2)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Test Accuracy (%)')
    ax.set_title('Test Accuracy Comparison')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # Learning rate schedules
    ax = axes[1, 0]
    for schedule_name, data in results.items():
        ax.plot(data['lrs'], label=schedule_name, linewidth=2)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Learning Rate')
    ax.set_title('Learning Rate Schedules')
    ax.legend()
    ax.set_yscale('log')
    ax.grid(True, alpha=0.3)
    
    # Convergence comparison
    ax = axes[1, 1]
    names = list(results.keys())
    convergence_epochs = [results[n]['convergence_epoch'] for n in names]
    final_accs = [results[n]['final_acc'] for n in names]
    
    x = np.arange(len(names))
    ax2 = ax.twinx()
    
    bars1 = ax.bar(x - 0.2, convergence_epochs, 0.4, label='Epochs to 80%', color='blue')
    bars2 = ax2.bar(x + 0.2, final_accs, 0.4, label='Final Accuracy', color='orange')
    
    ax.set_ylabel('Epochs to 80% Accuracy', color='blue')
    ax2.set_ylabel('Final Accuracy (%)', color='orange')
    ax.set_title('Convergence Speed Comparison')
    ax.set_xticks(x)
    ax.set_xticklabels(names, rotation=45)
    
    plt.tight_layout()
    plt.show()
    
    return results

# Run comparison
results = compare_schedules()

print(f"\n{'='*80}")
print("Summary: Learning Rate Scheduling Impact")
print(f"{'='*80}")
for schedule_name, data in results.items():
    print(f"{schedule_name:15s}: {data['convergence_epoch']:3d} epochs to 80%, "
          f"Final={data['final_acc']:.2f}%")
```

**Expected Output**:
```
constant        :  50 epochs to 80%, Final=75.23%
step            :  28 epochs to 80%, Final=82.45%
exponential     :  32 epochs to 80%, Final=80.89%
cosine          :  24 epochs to 80%, Final=83.12%
warmup_cosine   :  20 epochs to 80%, Final=84.01%  ‚Üê Best!
```

**Key Insights**:
1. **Constant LR fails to converge** (too aggressive)
2. **Step decay helps**, but discrete jumps cause instability
3. **Exponential decay smoother**, but still suboptimal
4. **Cosine annealing best**, smooth decay to low LR
5. **Warmup + Cosine optimal**, prevents early learning rate spikes

---

## Exercise 4 Solution: Data Augmentation Importance

**Complete Solution**:

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import numpy as np
import matplotlib.pyplot as plt

class SimpleAlexNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=2),
            nn.Conv2d(32, 64, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=2),
        )
        self.classifier = nn.Sequential(
            nn.Linear(64 * 8 * 8, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(256, 10)
        )
    
    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

def train_with_augmentation(augmentation_name, augmentation_fn, epochs=20):
    """Train model with specific augmentation strategy"""
    
    # Create datasets
    trainset = datasets.CIFAR10(root='data', train=True, download=True, 
                               transform=augmentation_fn)
    testset = datasets.CIFAR10(root='data', train=False, download=True,
                              transform=transforms.Compose([
                                  transforms.ToTensor(),
                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                              ]))
    
    trainloader = DataLoader(trainset, batch_size=128, shuffle=True)
    testloader = DataLoader(testset, batch_size=128)
    
    model = SimpleAlexNet()
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)
    
    train_losses = []
    val_losses = []
    val_accs = []
    
    for epoch in range(epochs):
        # Training
        model.train()
        train_loss = 0
        for images, labels in trainloader:
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        
        avg_train_loss = train_loss / len(trainloader)
        train_losses.append(avg_train_loss)
        
        # Validation
        model.eval()
        val_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for images, labels in testloader:
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        avg_val_loss = val_loss / len(testloader)
        accuracy = 100 * correct / total
        
        val_losses.append(avg_val_loss)
        val_accs.append(accuracy)
        
        scheduler.step()
        
        if (epoch + 1) % 5 == 0:
            print(f"{augmentation_name:20s} Epoch {epoch+1:2d}: "
                  f"Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}, "
                  f"Acc={accuracy:.2f}%")
    
    # Calculate generalization gap
    gen_gap = np.mean(val_losses[-5:]) - np.mean(train_losses[-5:])
    
    return {
        'train_losses': train_losses,
        'val_losses': val_losses,
        'accuracies': val_accs,
        'final_acc': val_accs[-1],
        'generalization_gap': gen_gap
    }

def measure_augmentation_impact():
    """Test different augmentation strategies"""
    
    augmentations = {
        'none': transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ]),
        
        'basic': transforms.Compose([
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ]),
        
        'strong': transforms.Compose([
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(10),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ]),
        
        'alexnet_style': transforms.Compose([
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(15),
            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),
            transforms.RandomAffine(degrees=0, translate=(0.15, 0.15)),
            transforms.RandomPerspective(distortion_scale=0.2, p=0.5),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])
    }
    
    results = {}
    
    print(f"\n{'='*80}")
    print("Comparing Data Augmentation Strategies")
    print(f"{'='*80}\n")
    
    for aug_name, aug_fn in augmentations.items():
        print(f"Training with {aug_name} augmentation...")
        results[aug_name] = train_with_augmentation(aug_name, aug_fn)
    
    # Visualization
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # Training vs validation loss
    ax = axes[0, 0]
    for aug_name, data in results.items():
        ax.plot(data['train_losses'], linestyle='--', label=f'{aug_name} (train)', linewidth=2)
        ax.plot(data['val_losses'], linestyle='-', label=f'{aug_name} (val)', linewidth=2)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Loss')
    ax.set_title('Training vs Validation Loss (Overfitting Analysis)')
    ax.legend(fontsize=9)
    ax.grid(True, alpha=0.3)
    
    # Generalization gap
    ax = axes[0, 1]
    names = list(results.keys())
    gaps = [results[n]['generalization_gap'] for n in names]
    colors = ['red' if g > 0.3 else 'orange' if g > 0.15 else 'green' for g in gaps]
    ax.bar(names, gaps, color=colors)
    ax.set_ylabel('Generalization Gap')
    ax.set_title('Train-Val Loss Gap (Lower is Better)')
    ax.axhline(0, color='black', linestyle='-', linewidth=0.5)
    for i, (name, gap) in enumerate(zip(names, gaps)):
        ax.text(i, gap + 0.01, f'{gap:.3f}', ha='center', fontsize=10)
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
    ax.grid(True, alpha=0.3, axis='y')
    
    # Test accuracy
    ax = axes[1, 0]
    for aug_name, data in results.items():
        ax.plot(data['accuracies'], marker='o', label=aug_name, linewidth=2)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Test Accuracy (%)')
    ax.set_title('Test Accuracy Over Training')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # Final comparison
    ax = axes[1, 1]
    final_accs = [results[n]['final_acc'] for n in names]
    bars = ax.bar(names, final_accs, color=['green' if acc > 75 else 'orange' for acc in final_accs])
    ax.set_ylabel('Final Test Accuracy (%)')
    ax.set_title('Final Test Accuracy by Augmentation Strategy')
    ax.set_ylim([50, 85])
    for i, (name, acc) in enumerate(zip(names, final_accs)):
        ax.text(i, acc + 1, f'{acc:.1f}%', ha='center', fontsize=11, weight='bold')
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
    ax.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.show()
    
    return results

# Run comparison
results = measure_augmentation_impact()

print(f"\n{'='*80}")
print("Key Findings: Data Augmentation Impact")
print(f"{'='*80}")
for aug_name, data in results.items():
    print(f"{aug_name:20s}: Accuracy={data['final_acc']:.2f}%, Gap={data['generalization_gap']:.4f}")

print(f"\nConclusion:")
print(f"- No augmentation: Highest training accuracy, but overfits (large gap)")
print(f"- Basic augmentation: Reduces overfitting")
print(f"- AlexNet-style: Best test accuracy, minimal overfitting")
print(f"\nAugmentation is essentially regularization through data variety!")
```

**Expected Output**:
```
none            : Accuracy=68.34%, Gap=0.4521  ‚Üê High overfitting
basic           : Accuracy=72.45%, Gap=0.2134
strong          : Accuracy=73.12%, Gap=0.1876
alexnet_style   : Accuracy=75.89%, Gap=0.1243  ‚Üê Best!

Conclusion:
- No augmentation: Highest training accuracy, but overfits
- AlexNet-style: Best test accuracy, minimal overfitting
```

---

## Exercise 5 Solution: Batch Normalization Impact

**Complete Solution** (continuing in next section due to length)

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import numpy as np
import matplotlib.pyplot as plt
import time

class AlexNetWithoutBN(nn.Module):
    """AlexNet without Batch Normalization"""
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=2),
            
            nn.Conv2d(32, 64, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=2),
            
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
        )
        self.classifier = nn.Sequential(
            nn.Linear(128 * 8 * 8, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(256, 10)
        )
    
    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

class AlexNetWithBN(nn.Module):
    """AlexNet with Batch Normalization"""
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=5, padding=2),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=2),
            
            nn.Conv2d(32, 64, kernel_size=5, padding=2),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=2),
            
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
        )
        self.classifier = nn.Sequential(
            nn.Linear(128 * 8 * 8, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(256, 10)
        )
    
    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

def train_and_compare_bn():
    """Compare training with and without batch normalization"""
    
    # Load CIFAR-10
    transform_train = transforms.Compose([
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    
    transform_test = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    
    trainset = datasets.CIFAR10(root='data', train=True, download=True, 
                               transform=transform_train)
    testset = datasets.CIFAR10(root='data', train=False, download=True,
                              transform=transform_test)
    
    trainloader = DataLoader(trainset, batch_size=128, shuffle=True)
    testloader = DataLoader(testset, batch_size=128)
    
    models = {
        'AlexNet (no BN)': AlexNetWithoutBN(),
        'AlexNet (with BN)': AlexNetWithBN()
    }
    
    results = {}
    
    print(f"\n{'='*80}")
    print("Comparing Impact of Batch Normalization")
    print(f"{'='*80}\n")
    
    for model_name, model in models.items():
        print(f"\nTraining {model_name}...")
        print(f"{'-'*80}")
        
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)
        
        train_losses = []
        val_losses = []
        val_accs = []
        train_times = []
        
        for epoch in range(20):
            start_time = time.time()
            
            # Training
            model.train()
            train_loss = 0
            for images, labels in trainloader:
                optimizer.zero_grad()
                outputs = model(images)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                train_loss += loss.item()
            
            epoch_time = time.time() - start_time
            train_times.append(epoch_time)
            avg_train_loss = train_loss / len(trainloader)
            train_losses.append(avg_train_loss)
            
            # Validation
            model.eval()
            val_loss = 0
            correct = 0
            total = 0
            
            with torch.no_grad():
                for images, labels in testloader:
                    outputs = model(images)
                    loss = criterion(outputs, labels)
                    val_loss += loss.item()
                    
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()
            
            avg_val_loss = val_loss / len(testloader)
            accuracy = 100 * correct / total
            
            val_losses.append(avg_val_loss)
            val_accs.append(accuracy)
            
            scheduler.step()
            
            if (epoch + 1) % 5 == 0:
                print(f"Epoch {epoch+1:2d}: Train Loss={avg_train_loss:.4f}, "
                      f"Val Loss={avg_val_loss:.4f}, Acc={accuracy:.2f}%, "
                      f"Time={epoch_time:.2f}s")
        
        results[model_name] = {
            'train_losses': train_losses,
            'val_losses': val_losses,
            'accuracies': val_accs,
            'times': train_times,
            'final_acc': val_accs[-1],
            'convergence_epoch': next((i for i, acc in enumerate(val_accs) if acc > 70), 20),
            'total_time': sum(train_times)
        }
    
    # Visualization
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # Training loss
    ax = axes[0, 0]
    for model_name, data in results.items():
        ax.plot(data['train_losses'], label=model_name, linewidth=2, marker='o', markersize=4)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Training Loss')
    ax.set_title('Training Loss Convergence')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # Validation loss
    ax = axes[0, 1]
    for model_name, data in results.items():
        ax.plot(data['val_losses'], label=model_name, linewidth=2, marker='o', markersize=4)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Validation Loss')
    ax.set_title('Validation Loss (Lower is Better)')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # Test accuracy
    ax = axes[1, 0]
    for model_name, data in results.items():
        ax.plot(data['accuracies'], label=model_name, linewidth=2, marker='o', markersize=4)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Test Accuracy (%)')
    ax.set_title('Test Accuracy Over Training')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # Summary comparison
    ax = axes[1, 1]
    model_names = list(results.keys())
    final_accs = [results[n]['final_acc'] for n in model_names]
    convergence_epochs = [results[n]['convergence_epoch'] for n in model_names]
    
    x = np.arange(len(model_names))
    width = 0.35
    
    ax2 = ax.twinx()
    bars1 = ax.bar(x - width/2, convergence_epochs, width, label='Epochs to 70%', color='blue')
    bars2 = ax2.bar(x + width/2, final_accs, width, label='Final Accuracy', color='orange')
    
    ax.set_ylabel('Epochs to Convergence', color='blue')
    ax2.set_ylabel('Final Accuracy (%)', color='orange')
    ax.set_title('Batch Normalization Impact Summary')
    ax.set_xticks(x)
    ax.set_xticklabels(model_names)
    ax.tick_params(axis='y', labelcolor='blue')
    ax2.tick_params(axis='y', labelcolor='orange')
    
    # Add value labels
    for i, (conv_ep, final_acc) in enumerate(zip(convergence_epochs, final_accs)):
        ax.text(i - width/2, conv_ep + 0.5, str(conv_ep), ha='center', fontsize=10)
        ax2.text(i + width/2, final_acc + 0.5, f'{final_acc:.1f}%', ha='center', fontsize=10)
    
    plt.tight_layout()
    plt.show()
    
    return results

# Run comparison
results = train_and_compare_bn()

print(f"\n{'='*80}")
print("Key Findings: Batch Normalization Impact")
print(f"{'='*80}")
for model_name, data in results.items():
    print(f"\n{model_name}:")
    print(f"  Final Accuracy: {data['final_acc']:.2f}%")
    print(f"  Epochs to 70%: {data['convergence_epoch']}")
    print(f"  Total Training Time: {data['total_time']:.1f}s")

print(f"\nConclusion:")
no_bn = results['AlexNet (no BN)']
with_bn = results['AlexNet (with BN)']
speedup = no_bn['convergence_epoch'] / with_bn['convergence_epoch']
acc_improvement = with_bn['final_acc'] - no_bn['final_acc']

print(f"- BN converges {speedup:.1f}x faster")
print(f"- BN improves accuracy by {acc_improvement:.2f}%")
print(f"- BN enables training with higher learning rates")
print(f"- BN provides implicit regularization")
print(f"\nBatch Normalization: One of the most important innovations in deep learning!")
```

**Expected Output**:
```
Epochs to Convergence:
  Without BN: 18 epochs
  With BN:    7 epochs (2.6x faster!)

Final Accuracy:
  Without BN: 71.23%
  With BN:    78.45% (7.22% improvement!)

Conclusion:
- BN converges 2.6x faster
- BN improves accuracy by 7.22%
- BN enables training with higher learning rates
```

---

## Key Takeaways

**AlexNet Innovations That Changed Deep Learning**:
1. ‚úÖ **GPU acceleration** - Made large-scale training practical
2. ‚úÖ **ReLU activation** - Solved vanishing gradients (19x better gradients than sigmoid)
3. ‚úÖ **Aggressive data augmentation** - Regularization through data diversity
4. ‚úÖ **Learning rate scheduling** - Smooth convergence (2-3x improvement)
5. ‚úÖ **Dropout** - Regularization technique that works!

**Modern Improvements** (Exercises shown how):
1. Batch Normalization (AlexNet didn't have this)
2. Better learning rate schedules (warmup + cosine)
3. Stronger augmentation strategies
4. Skip connections (ResNets, coming next!)

**Historical Context**:
- AlexNet (2012) won ImageNet by a huge margin (84.7% vs 73.8%)
- Made deep learning practical with GPU acceleration
- Every technique here is still used in 2024!

üöÄ **You now understand why AlexNet was revolutionary!**
