{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 28: CS231n -- CNNs for Visual Recognition\n",
    "\n",
    "> Stanford CS231n Course Notes -- Andrej Karpathy, Fei-Fei Li\n",
    "\n",
    "This notebook walks through core CNN components from scratch:\n",
    "1. Convolution layer (naive + im2col)\n",
    "2. Max pooling layer\n",
    "3. ReLU activation\n",
    "4. SimpleCNN end-to-end\n",
    "5. VGGNet-16 parameter analysis\n",
    "\n",
    "**Reference:** https://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams[\"font.size\"] = 12"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Output Size Formula\n",
    "\n",
    "The most important equation in CNNs (from CS231n):\n",
    "\n",
    "$$\\text{output size} = \\frac{W - F + 2P}{S} + 1$$\n",
    "\n",
    "Where:\n",
    "- **W** = input size\n",
    "- **F** = filter size\n",
    "- **P** = padding\n",
    "- **S** = stride\n",
    "\n",
    "If this produces a non-integer, the hyperparameters are invalid."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def output_size(W, F, P, S):\n",
    "    \"\"\"CS231n output size formula.\"\"\"\n",
    "    return (W - F + 2*P) // S + 1\n",
    "\n",
    "# Common cases from CS231n:\n",
    "print(\"Case 1: 32x32 input, 3x3 filter, pad=1, stride=1\")\n",
    "print(f\"  Output: {output_size(32, 3, 1, 1)}x{output_size(32, 3, 1, 1)}  (preserved)\")\n",
    "\n",
    "print(\"\\nCase 2: AlexNet first layer - 227x227, 11x11 filter, stride=4\")\n",
    "print(f\"  Output: {output_size(227, 11, 0, 4)}x{output_size(227, 11, 0, 4)}\")\n",
    "\n",
    "print(\"\\nCase 3: 2x2 max pooling stride 2 on 32x32\")\n",
    "print(f\"  Output: {output_size(32, 2, 0, 2)}x{output_size(32, 2, 0, 2)}  (halved)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naive Convolution Forward Pass\n",
    "\n",
    "The convolution slides each filter across the input volume,\n",
    "computing a dot product at every spatial position."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def conv_forward_naive(x, w, b, stride=1, pad=0):\n",
    "    \"\"\"Naive convolution: 4 nested loops.\"\"\"\n",
    "    N, C, H, W = x.shape\n",
    "    K, _, FH, FW = w.shape\n",
    "    H_out = (H - FH + 2*pad) // stride + 1\n",
    "    W_out = (W - FW + 2*pad) // stride + 1\n",
    "    \n",
    "    x_pad = np.pad(x, ((0,0),(0,0),(pad,pad),(pad,pad)), mode=\"constant\")\n",
    "    out = np.zeros((N, K, H_out, W_out))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "            for i in range(H_out):\n",
    "                for j in range(W_out):\n",
    "                    h_s = i * stride\n",
    "                    w_s = j * stride\n",
    "                    region = x_pad[n, :, h_s:h_s+FH, w_s:w_s+FW]\n",
    "                    out[n, k, i, j] = np.sum(region * w[k]) + b[k]\n",
    "    return out\n",
    "\n",
    "# Test\n",
    "np.random.seed(42)\n",
    "x = np.random.randn(1, 3, 8, 8)\n",
    "w = np.random.randn(4, 3, 3, 3)\n",
    "b = np.zeros(4)\n",
    "\n",
    "out = conv_forward_naive(x, w, b, stride=1, pad=1)\n",
    "print(f\"Input shape:  {x.shape}\")\n",
    "print(f\"Filter shape: {w.shape}\")\n",
    "print(f\"Output shape: {out.shape}\")\n",
    "print(f\"Expected:     (1, 4, 8, 8)  -- pad=1 preserves spatial size\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. im2col: The Fast Convolution Trick\n",
    "\n",
    "The **im2col** trick reshapes overlapping input patches into columns,\n",
    "then convolution becomes a single matrix multiply."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def im2col(x, FH, FW, stride=1, pad=0):\n",
    "    \"\"\"Reshape input patches into columns for matrix multiply.\"\"\"\n",
    "    N, C, H, W = x.shape\n",
    "    H_out = (H - FH + 2*pad) // stride + 1\n",
    "    W_out = (W - FW + 2*pad) // stride + 1\n",
    "    x_pad = np.pad(x, ((0,0),(0,0),(pad,pad),(pad,pad)), mode=\"constant\")\n",
    "    cols = np.zeros((N, C, FH, FW, H_out, W_out))\n",
    "    for i in range(FH):\n",
    "        for j in range(FW):\n",
    "            cols[:, :, i, j, :, :] = x_pad[:, :, i:i+stride*H_out:stride, j:j+stride*W_out:stride]\n",
    "    return cols.reshape(N, C*FH*FW, H_out*W_out)\n",
    "\n",
    "def conv_forward_im2col(x, w, b, stride=1, pad=0):\n",
    "    \"\"\"Fast convolution via im2col + matrix multiply.\"\"\"\n",
    "    N, C, H, W = x.shape\n",
    "    K, _, FH, FW = w.shape\n",
    "    H_out = (H - FH + 2*pad) // stride + 1\n",
    "    W_out = (W - FW + 2*pad) // stride + 1\n",
    "    cols = im2col(x, FH, FW, stride, pad)\n",
    "    w_flat = w.reshape(K, -1)\n",
    "    out = np.zeros((N, K, H_out*W_out))\n",
    "    for n in range(N):\n",
    "        out[n] = w_flat @ cols[n] + b.reshape(-1, 1)\n",
    "    return out.reshape(N, K, H_out, W_out)\n",
    "\n",
    "# Compare naive vs im2col\n",
    "out_naive = conv_forward_naive(x, w, b, stride=1, pad=1)\n",
    "out_fast = conv_forward_im2col(x, w, b, stride=1, pad=1)\n",
    "print(f\"Max difference: {np.max(np.abs(out_naive - out_fast)):.2e}\")\n",
    "print(\"Both methods produce identical results.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Max Pooling\n",
    "\n",
    "CS231n: *\"The most common form is a pooling layer with filters of size 2x2\n",
    "applied with a stride of 2, which discards exactly 75% of the activations.\"*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def max_pool(x, pool_size=2, stride=2):\n",
    "    \"\"\"2x2 max pooling -- halves spatial dimensions.\"\"\"\n",
    "    N, C, H, W = x.shape\n",
    "    H_out = (H - pool_size) // stride + 1\n",
    "    W_out = (W - pool_size) // stride + 1\n",
    "    out = np.zeros((N, C, H_out, W_out))\n",
    "    for i in range(H_out):\n",
    "        for j in range(W_out):\n",
    "            h_s, w_s = i*stride, j*stride\n",
    "            out[:, :, i, j] = np.max(\n",
    "                x[:, :, h_s:h_s+pool_size, w_s:w_s+pool_size], axis=(2,3)\n",
    "            )\n",
    "    return out\n",
    "\n",
    "pool_in = np.random.randn(1, 4, 8, 8)\n",
    "pool_out = max_pool(pool_in)\n",
    "print(f\"Input:  {pool_in.shape}\")\n",
    "print(f\"Output: {pool_out.shape}  -- halved spatial dimensions\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SimpleCNN: Full Forward Pass\n",
    "\n",
    "Architecture: CONV(3x3, 8) -> ReLU -> Pool -> CONV(3x3, 16) -> ReLU -> Pool -> FC(10)\n",
    "\n",
    "A minimal CNN for CIFAR-10 (32x32x3 input, 10 classes)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "class SimpleCNN:\n",
    "    \"\"\"Minimal CNN: 2 conv layers + 1 FC layer.\"\"\"\n",
    "    def __init__(self):\n",
    "        scale = 0.01\n",
    "        self.params = {\n",
    "            \"W1\": np.random.randn(8, 3, 3, 3) * scale,\n",
    "            \"b1\": np.zeros(8),\n",
    "            \"W2\": np.random.randn(16, 8, 3, 3) * scale,\n",
    "            \"b2\": np.zeros(16),\n",
    "            \"W3\": np.random.randn(16 * 8 * 8, 10) * scale,\n",
    "            \"b3\": np.zeros(10),\n",
    "        }\n",
    "    \n",
    "    def forward(self, x):\n",
    "        p = self.params\n",
    "        # CONV1 -> ReLU -> Pool\n",
    "        h1 = conv_forward_im2col(x, p[\"W1\"], p[\"b1\"], stride=1, pad=1)\n",
    "        h1 = relu(h1)\n",
    "        h1 = max_pool(h1)  # 32->16\n",
    "        # CONV2 -> ReLU -> Pool\n",
    "        h2 = conv_forward_im2col(h1, p[\"W2\"], p[\"b2\"], stride=1, pad=1)\n",
    "        h2 = relu(h2)\n",
    "        h2 = max_pool(h2)  # 16->8\n",
    "        # FC\n",
    "        h2_flat = h2.reshape(x.shape[0], -1)\n",
    "        scores = h2_flat @ p[\"W3\"] + p[\"b3\"]\n",
    "        return scores\n",
    "\n",
    "model = SimpleCNN()\n",
    "dummy = np.random.randn(2, 3, 32, 32)\n",
    "scores = model.forward(dummy)\n",
    "print(f\"Input:       {dummy.shape}\")\n",
    "print(f\"Scores:      {scores.shape}\")\n",
    "print(f\"Predictions: {np.argmax(scores, axis=1)}\")\n",
    "total = sum(p.size for p in model.params.values())\n",
    "print(f\"Total params: {total:,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizing Filters and Activations\n",
    "\n",
    "First-layer filters operate on RGB pixels and can be visualized directly.\n",
    "Deeper filters operate on activation maps and are harder to interpret."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize first-layer filters\n",
    "filters = model.params[\"W1\"]  # (8, 3, 3, 3)\n",
    "\n",
    "fig, axes = plt.subplots(1, 8, figsize=(16, 2))\n",
    "fig.suptitle(\"First-Layer Filters (random init)\", fontweight=\"bold\")\n",
    "for i in range(8):\n",
    "    f = filters[i].transpose(1, 2, 0)  # CHW -> HWC\n",
    "    f = (f - f.min()) / (f.max() - f.min() + 1e-8)\n",
    "    axes[i].imshow(f)\n",
    "    axes[i].set_title(f\"F{i}\", fontsize=9)\n",
    "    axes[i].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Activation maps after CONV1\n",
    "image = np.random.randn(1, 3, 32, 32)\n",
    "act = relu(conv_forward_im2col(image, model.params[\"W1\"], model.params[\"b1\"], stride=1, pad=1))\n",
    "\n",
    "fig, axes = plt.subplots(1, 8, figsize=(16, 2))\n",
    "fig.suptitle(\"Activation Maps After CONV1 + ReLU\", fontweight=\"bold\")\n",
    "for i in range(8):\n",
    "    axes[i].imshow(act[0, i], cmap=\"viridis\")\n",
    "    axes[i].set_title(f\"Map {i}\", fontsize=9)\n",
    "    axes[i].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. VGGNet-16 Parameter Analysis\n",
    "\n",
    "CS231n's key insight: **89% of VGGNet's parameters are in the FC layers**, but\n",
    "most memory is consumed by the early CONV layers."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# VGGNet-16 layer specs: (name, in_depth, out_depth, filter_size)\n",
    "vgg = [\n",
    "    (\"CONV3-64\", 3, 64, 3), (\"CONV3-64\", 64, 64, 3),\n",
    "    (\"CONV3-128\", 64, 128, 3), (\"CONV3-128\", 128, 128, 3),\n",
    "    (\"CONV3-256\", 128, 256, 3), (\"CONV3-256\", 256, 256, 3), (\"CONV3-256\", 256, 256, 3),\n",
    "    (\"CONV3-512\", 256, 512, 3), (\"CONV3-512\", 512, 512, 3), (\"CONV3-512\", 512, 512, 3),\n",
    "    (\"CONV3-512\", 512, 512, 3), (\"CONV3-512\", 512, 512, 3), (\"CONV3-512\", 512, 512, 3),\n",
    "]\n",
    "fc = [\n",
    "    (\"FC-4096\", (7*7*512+1)*4096),\n",
    "    (\"FC-4096\", (4096+1)*4096),\n",
    "    (\"FC-1000\", (4096+1)*1000),\n",
    "]\n",
    "\n",
    "names, params = [], []\n",
    "for name, d_in, d_out, f in vgg:\n",
    "    names.append(name)\n",
    "    params.append((f*f*d_in + 1) * d_out)\n",
    "for name, p in fc:\n",
    "    names.append(name)\n",
    "    params.append(p)\n",
    "\n",
    "total = sum(params)\n",
    "print(f\"VGGNet-16 Total: {total:,} parameters\\n\")\n",
    "for n, p in zip(names, params):\n",
    "    print(f\"  {n:15s} {p:>12,}  ({p/total*100:5.1f}%)\")\n",
    "\n",
    "conv_p = sum(p for n, p in zip(names, params) if n.startswith('CONV'))\n",
    "fc_p = sum(p for n, p in zip(names, params) if n.startswith('FC'))\n",
    "print(f\"\\n  CONV total: {conv_p:>12,}  ({conv_p/total*100:.1f}%)\")\n",
    "print(f\"  FC total:   {fc_p:>12,}  ({fc_p/total*100:.1f}%)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize parameter distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle(\"VGGNet-16: Where Do Parameters Live? (from CS231n)\", fontweight=\"bold\")\n",
    "\n",
    "colors = [\"steelblue\" if n.startswith(\"CONV\") else \"coral\" for n in names]\n",
    "ax1.barh(range(len(names)), [p/1e6 for p in params], color=colors, alpha=0.8)\n",
    "ax1.set_yticks(range(len(names)))\n",
    "ax1.set_yticklabels(names, fontsize=9)\n",
    "ax1.set_xlabel(\"Parameters (Millions)\")\n",
    "ax1.set_title(\"FC layers dominate\")\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "pool_sizes = [224, 112, 56, 28, 14, 7]\n",
    "ax2.bar(range(len(pool_sizes)), pool_sizes, color=\"seagreen\", alpha=0.7)\n",
    "ax2.set_xticks(range(len(pool_sizes)))\n",
    "ax2.set_xticklabels([\"Input\", \"Pool1\", \"Pool2\", \"Pool3\", \"Pool4\", \"Pool5\"])\n",
    "ax2.set_ylabel(\"Spatial Size\")\n",
    "ax2.set_title(\"Spatial dims halve at each pool\")\n",
    "for i, v in enumerate(pool_sizes):\n",
    "    ax2.text(i, v+3, str(v), ha=\"center\", fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Output size formula**: `(W - F + 2P) / S + 1` -- memorize this\n",
    "2. **Parameter sharing**: Each filter uses the same weights across the entire input\n",
    "3. **im2col trick**: Reshapes convolution into matrix multiplication for speed\n",
    "4. **VGGNet insight**: 89% of params in FC layers; most memory in early CONV layers\n",
    "5. **Architecture pattern**: Spatial dims shrink while depth grows\n",
    "\n",
    "---\n",
    "\n",
    "Next: Try the exercises in `exercises/` to implement these from scratch yourself."
   ]
  }
 ]
}