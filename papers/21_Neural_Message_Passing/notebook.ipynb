{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 21: Neural Message Passing for Quantum Chemistry\n",
    "\n",
    "> Gilmer, Schoenholz, Riley, Vinyals, Dahl (2017) — [arXiv:1704.01212](https://arxiv.org/abs/1704.01212)\n",
    "\n",
    "This notebook walks through the MPNN framework from the paper:\n",
    "1. Build molecular graphs from atom and bond data\n",
    "2. Implement the three design choices: message function, update function, readout\n",
    "3. Train an MPNN on synthetic molecular data\n",
    "4. Visualize message passing and compare architecture variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from implementation import (\n",
    "    MPNN,\n",
    "    MolecularGraph,\n",
    "    BatchedGraph,\n",
    "    ATOM_TYPES,\n",
    "    BOND_TYPES,\n",
    "    generate_dataset,\n",
    "    generate_synthetic_molecule,\n",
    "    batch_graphs,\n",
    "    train_epoch,\n",
    "    evaluate,\n",
    "    summarize_model,\n",
    "    SimpleMessage,\n",
    "    MatrixMessage,\n",
    "    EdgeNetwork,\n",
    "    SumReadout,\n",
    "    Set2SetReadout,\n",
    "    scatter_sum,\n",
    ")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "print(f'PyTorch {torch.__version__}')\n",
    "print(f'Device: {\"cuda\" if torch.cuda.is_available() else \"cpu\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Molecular Graphs\n",
    "\n",
    "A molecule is represented as a graph (Section 2):\n",
    "- **Nodes** = atoms, with features (one-hot atom type: H, C, N, O, F)\n",
    "- **Edges** = bonds, with features (one-hot bond type: single, double, triple, aromatic)\n",
    "- **Target** = property values to predict (energy, dipole moment, etc.)\n",
    "\n",
    "Let's generate a synthetic molecule and inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = generate_synthetic_molecule(min_atoms=6, max_atoms=10, n_targets=3, seed=42)\n",
    "\n",
    "print(f'Atoms: {mol.num_nodes}')\n",
    "print(f'Bonds (directed): {mol.num_edges}')\n",
    "print(f'Node features shape: {mol.node_features.shape}')\n",
    "print(f'Edge index shape: {mol.edge_index.shape}')\n",
    "print(f'Edge features shape: {mol.edge_features.shape}')\n",
    "print(f'Target: {mol.target}')\n",
    "\n",
    "# Decode atom types\n",
    "atom_indices = mol.node_features.argmax(dim=1)\n",
    "atom_names = [ATOM_TYPES[i] for i in atom_indices.tolist()]\n",
    "print(f'\\nAtom types: {atom_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Message Functions (Sections 3-4)\n",
    "\n",
    "The message function $M(h_v, h_w, e_{vw})$ determines how information flows\n",
    "from neighbor $w$ to node $v$. Three variants:\n",
    "\n",
    "| Variant | Formula | Paper Section |\n",
    "|---------|---------|---------------|\n",
    "| Simple | $M = h_w$ | 3 (Duvenaud) |\n",
    "| Matrix | $M = A_{e_{vw}} h_w$ | 3 (Li et al.) |\n",
    "| Edge Network | $M = A(e_{vw}) h_w$ | 4.1 (this paper) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 16\n",
    "edge_dim = len(BOND_TYPES)  # 4\n",
    "n_edges = 10\n",
    "\n",
    "# Create fake data\n",
    "h_v = torch.randn(n_edges, hidden_dim)\n",
    "h_w = torch.randn(n_edges, hidden_dim)\n",
    "edge_feats = torch.zeros(n_edges, edge_dim)\n",
    "edge_feats.scatter_(1, torch.randint(0, edge_dim, (n_edges, 1)), 1.0)\n",
    "\n",
    "# Compare message functions\n",
    "for name, cls in [('Simple', SimpleMessage), ('Matrix', MatrixMessage), ('EdgeNetwork', EdgeNetwork)]:\n",
    "    msg_fn = cls(hidden_dim, edge_dim)\n",
    "    out = msg_fn(h_v, h_w, edge_feats)\n",
    "    print(f'{name:12s} output shape: {out.shape}, mean: {out.mean():.4f}, std: {out.std():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Full MPNN Training\n",
    "\n",
    "Now we train a complete MPNN on synthetic molecular data.\n",
    "Architecture: edge network + GRU + Set2Set (the best variant from Table 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "dataset = generate_dataset(n_molecules=400, n_targets=3, seed=42)\n",
    "train_data = dataset[:320]\n",
    "test_data = dataset[320:]\n",
    "\n",
    "print(f'Train: {len(train_data)}, Test: {len(test_data)}')\n",
    "\n",
    "# Create model\n",
    "model = MPNN(\n",
    "    node_dim=len(ATOM_TYPES),\n",
    "    edge_dim=len(BOND_TYPES),\n",
    "    hidden_dim=64,\n",
    "    output_dim=3,\n",
    "    n_messages=3,\n",
    "    message_type='edge_network',\n",
    "    readout_type='set2set',\n",
    "    set2set_steps=6\n",
    ")\n",
    "\n",
    "print(summarize_model(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "n_epochs = 30\n",
    "\n",
    "train_losses = []\n",
    "test_maes = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train_epoch(model, train_data, optimizer, batch_size=32)\n",
    "    metrics = evaluate(model, test_data, batch_size=32)\n",
    "    train_losses.append(loss)\n",
    "    test_maes.append(metrics['mae'])\n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        print(f'Epoch {epoch:2d}: train_loss={loss:.4f}, test_mae={metrics[\"mae\"]:.4f}')\n",
    "\n",
    "print(f'\\nFinal test MAE: {test_maes[-1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(train_losses)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Training Loss (MAE)')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(test_maes, color='orange')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Test MAE')\n",
    "axes[1].set_title('Test MAE')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "fig.suptitle('MPNN Training (Gilmer et al. 2017)', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparing Message Function Variants\n",
    "\n",
    "Let's compare the three message function variants to see how they affect\n",
    "learning. On real QM9 data, the edge network consistently outperforms\n",
    "simpler variants (Table 2). On synthetic data, differences may be smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_results = {}\n",
    "\n",
    "for msg_type in ['simple', 'matrix', 'edge_network']:\n",
    "    torch.manual_seed(42)\n",
    "    m = MPNN(\n",
    "        node_dim=len(ATOM_TYPES), edge_dim=len(BOND_TYPES),\n",
    "        hidden_dim=32, output_dim=3, n_messages=3,\n",
    "        message_type=msg_type, readout_type='set2set'\n",
    "    )\n",
    "    opt = torch.optim.Adam(m.parameters(), lr=1e-3)\n",
    "    losses = []\n",
    "    for epoch in range(20):\n",
    "        l = train_epoch(m, train_data, opt, batch_size=32)\n",
    "        losses.append(l)\n",
    "    final_mae = evaluate(m, test_data)['mae']\n",
    "    comparison_results[msg_type] = {'losses': losses, 'final_mae': final_mae}\n",
    "    print(f'{msg_type:15s}: final MAE = {final_mae:.4f}')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "for msg_type, result in comparison_results.items():\n",
    "    ax.plot(result['losses'], label=msg_type)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Training Loss')\n",
    "ax.set_title('Message Function Comparison (Sections 3-4)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Message Passing Receptive Field\n",
    "\n",
    "After $T$ message passing rounds, each node has received information from\n",
    "all nodes within $T$ hops. This is the \"receptive field\" of the node.\n",
    "\n",
    "For QM9 molecules (diameter typically 3-5 bonds), $T = 6$ ensures every\n",
    "atom can communicate with every other atom (Section 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from visualization import plot_message_passing_steps, plot_molecule\n",
    "    mol_vis = generate_synthetic_molecule(min_atoms=8, max_atoms=12, seed=42)\n",
    "    plot_molecule(mol_vis, title=f'Synthetic Molecule ({mol_vis.num_nodes} atoms)')\n",
    "    plt.show()\n",
    "    plot_message_passing_steps(mol_vis, n_steps=3)\n",
    "    plt.show()\n",
    "except ImportError as e:\n",
    "    print(f'networkx required for molecule visualization: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **MPNN is a unifying framework**: message function $M$, update function $U$, readout $R$ — three choices that define the model (Section 2)\n",
    "2. **Edge network handles continuous features**: maps edge attributes to $d \\times d$ transformation matrices (Section 4.1)\n",
    "3. **Set2Set beats sum pooling**: iterative attention captures the distribution of node states, not just their sum (Section 4.3)\n",
    "4. **Chemical accuracy on 11/13 targets**: with 3D coordinates as input; 5/13 without coordinates (Table 2)\n",
    "5. **The framework became standard**: virtually every GNN paper since 2017 defines models in MPNN terms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
