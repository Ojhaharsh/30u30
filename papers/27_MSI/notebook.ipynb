{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 27: Machine Super Intelligence\n",
    "\n",
    "> Shane Legg (2008) â€” [Machine Super Intelligence](https://www.vetta.org/documents/Machine_Super_Intelligence.pdf)\n",
    "\n",
    "Welcome to Day 27. Today we transition from the mathematical theory of information (Day 26) to the mathematical theory of *intelligence*. \n",
    "\n",
    "Shane Legg's thesis formalizes the idea that intelligence is not about being good at a specific game (like Chess), but about being a **Generalist** who can adapt to any reward-summarizing environment.\n",
    "\n",
    "## What We'll Do\n",
    "1. **The formal definition**: Implementing $\\Upsilon(\\pi)$.\n",
    "2. **Occam's weighting**: Visualizing why $2^{-K}$ is the 'Gold Standard' for general intelligence.\n",
    "3. **Agent Showdown**: Comparing Random vs. Specialized RL vs. Compression-based Agents.\n",
    "4. **Simulation**: Proving the Invariance Theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementation import (\n",
    "    UniversalIntelligenceMeasure, \n",
    "    GridWorld, \n",
    "    PatternSequence, \n",
    "    RandomAgent, \n",
    "    SimpleRLAgent, \n",
    "    PredictiveAgent\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(42)\n",
    "print(\"Framework loaded. Ready for evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Intelligence Formula\n",
    "\n",
    "Shane Legg defines $\\Upsilon(\\pi)$ as the weighted average of performance over all computable environments $\\mu$.\n",
    "\n",
    "$$\\Upsilon(\\pi) = \\sum_{\\mu \\in E} 2^{-K(\\mu)} V_{\\mu}^\\pi$$\n",
    "\n",
    "Let's visualize the **Universal Weighting** ($2^{-K}$). This is why 'Simple' matters more than 'Noisy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complexities = np.arange(1, 11)\n",
    "weights = 2.0**(-complexities)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(complexities, weights, color='salmon', alpha=0.7)\n",
    "plt.yscale('log')\n",
    "plt.title(\"The Universal Prior (2^-K)\")\n",
    "plt.xlabel(\"Environment Complexity K\")\n",
    "plt.ylabel(\"Weight (Log Scale)\")\n",
    "plt.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Note: An environment of complexity 10 is {2**8}x less important than one of complexity 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining the Test Suite\n",
    "\n",
    "We use a mix of GridWorlds (navigation) and PatternSequences (induction) as our proxy for the space $E$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = [\n",
    "    GridWorld(size=3),        # K=3 (Simple navigation)\n",
    "    GridWorld(size=8),        # K=8 (Medium navigation)\n",
    "    PatternSequence([0, 1]),  # K=4 (Simple induction)\n",
    "    PatternSequence([0, 1, 2, 3, 0, 1, 2]), # K=14 (Complex pattern)\n",
    "]\n",
    "\n",
    "measure = UniversalIntelligenceMeasure(envs)\n",
    "print(f\"Test suite initialized with {len(envs)} environments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Benchmark Showdown\n",
    "\n",
    "We compare three different philosophies of intelligence:\n",
    "1. **Baseline**: Acts randomly.\n",
    "2. **Simple RL (Q-Table)**: Specialized learner.\n",
    "3. **Predictive Agent**: Acts as a proxy for Solomonoff Induction (Compression-based)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = {\n",
    "    \"Random\": RandomAgent(),\n",
    "    \"Simple RL\": SimpleRLAgent(),\n",
    "    \"Predictive\": PredictiveAgent()\n",
    "}\n",
    "\n",
    "scores = {}\n",
    "for name, agent in agents.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    # We give them a generous 50 episodes to show their learning capacity\n",
    "    res = measure.evaluate(agent, episodes=50)\n",
    "    scores[name] = res['upsilon_normalized']\n",
    "    print(f\"  {name} Upsilon: {scores[name]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discussion: Why did the Predictive Agent win?\n",
    "\n",
    "In Legg's theory, the core of intelligence is **Generalization**. \n",
    "\n",
    "- The **Simple RL** agent tries to maximize reward through trial and error.\n",
    "- The **Predictive Agent** tries to 'compress' the environment's history into a map. \n",
    "\n",
    "Because many environments share underlying logical structures (cycles, grids), the ability to build an internal model (compression) allows the Predictive agent to solve new environments faster than a pure tabula-rasa RL agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Non-Anthropocentric**: Upsilon doesn't care if you're a human or a computer. It only cares if you achieve goals.\n",
    "2. **Simple is Universal**: The weight $2^{-K}$ formalizes Occam's Razor as a fundamental law of intelligence.\n",
    "3. **The Limit**: AIXI is the 'Perfect' agent with maximum Upsilon, but it is non-computable because checking all possible programs takes infinite time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
