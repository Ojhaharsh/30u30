{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b3ea99f",
   "metadata": {},
   "source": [
    "# Day 11: Dilated Convolutions - Multi-Scale Context Without Losing Resolution üéØ\n",
    "\n",
    "Welcome to Day 11 of 30 Papers in 30 Days!\n",
    "\n",
    "Today we're exploring **Dilated Convolutions** (also called Atrous Convolutions) - the technique that revolutionized semantic segmentation by capturing multi-scale context without sacrificing resolution. It's like having multiple receptive field sizes in one network!\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **The Resolution Problem**: Why pooling loses critical spatial information\n",
    "2. **Dilated Convolutions**: Expanding receptive fields with \"holes\"\n",
    "3. **ASPP (Atrous Spatial Pyramid Pooling)**: Multi-scale feature extraction\n",
    "4. **Semantic Segmentation**: Pixel-perfect predictions\n",
    "5. **WaveNet Connection**: How dilated convs revolutionized audio too\n",
    "6. **Implementation**: Building dilated conv networks from scratch\n",
    "\n",
    "## The Big Idea (in 30 seconds)\n",
    "\n",
    "**Problem**: Pooling reduces resolution. Upsampling loses fine details.\n",
    "\n",
    "**Solution**: Use dilated convolutions - convolutions with gaps (\"holes\") between kernel elements!\n",
    "\n",
    "**Magic**: Exponentially expand receptive field WITHOUT reducing resolution!\n",
    "\n",
    "**Result**: See both local details AND global context simultaneously!\n",
    "\n",
    "Let's dive into the world of multi-scale perception! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b11706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Add current directory to path\n",
    "sys.path.append('.')\n",
    "\n",
    "# Import our dilated convolution implementation\n",
    "from implementation import DilatedConvNet, ASPPModule, DilatedResidualBlock\n",
    "from visualization import DilatedConvVisualizer, visualize_receptive_field\n",
    "from train_minimal import train_segmentation, create_segmentation_dataset\n",
    "\n",
    "# Set up device and seeds\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"üî• Using device: {device}\")\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(\"üéØ Ready to explore dilated convolutions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07373101",
   "metadata": {},
   "source": [
    "## Part 1: Understanding the Problem - Resolution vs Receptive Field\n",
    "\n",
    "Traditional CNNs face a dilemma: to increase receptive field, you need pooling. But pooling reduces resolution, which is terrible for dense prediction tasks like segmentation!\n",
    "\n",
    "Let's visualize this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b86732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the resolution-receptive field dilemma\n",
    "def demonstrate_resolution_problem():\n",
    "    \"\"\"Show why pooling is problematic for dense predictions.\"\"\"\n",
    "    \n",
    "    print(\"üî¨ The Resolution vs Receptive Field Dilemma...\")\n",
    "    \n",
    "    # Create a simple image\n",
    "    img = torch.zeros(1, 1, 64, 64)\n",
    "    \n",
    "    # Add some patterns\n",
    "    img[0, 0, 10:20, 10:20] = 1.0  # Small object\n",
    "    img[0, 0, 30:50, 30:50] = 0.7  # Medium object\n",
    "    img[0, 0, 5:8, 50:60] = 1.0    # Thin object\n",
    "    \n",
    "    # Standard CNN with pooling\n",
    "    conv_pool_net = nn.Sequential(\n",
    "        nn.Conv2d(1, 16, 3, 1, 1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),  # 64 -> 32\n",
    "        nn.Conv2d(16, 32, 3, 1, 1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),  # 32 -> 16\n",
    "        nn.Conv2d(32, 64, 3, 1, 1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),  # 16 -> 8\n",
    "    )\n",
    "    \n",
    "    # Process image\n",
    "    with torch.no_grad():\n",
    "        output_pooled = conv_pool_net(img)\n",
    "    \n",
    "    print(f\"\\nüìê Architecture with Pooling:\")\n",
    "    print(f\"  Input shape: {list(img.shape)}\")\n",
    "    print(f\"  Output shape: {list(output_pooled.shape)}\")\n",
    "    print(f\"  ‚ùå Resolution reduced by 8x! (64 -> 8)\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Original\n",
    "    axes[0].imshow(img[0, 0], cmap='gray')\n",
    "    axes[0].set_title('Original Image (64√ó64)', fontsize=12, weight='bold')\n",
    "    axes[0].axis('off')\n",
    "    axes[0].text(32, -3, 'Fine Details ‚úì', ha='center', fontsize=10, color='green', weight='bold')\n",
    "    \n",
    "    # After pooling\n",
    "    pooled_vis = F.interpolate(output_pooled.mean(dim=1, keepdim=True), \n",
    "                               size=(64, 64), mode='nearest')\n",
    "    axes[1].imshow(pooled_vis[0, 0], cmap='viridis')\n",
    "    axes[1].set_title('After Pooling (8√ó8 ‚Üí upsampled)', fontsize=12, weight='bold')\n",
    "    axes[1].axis('off')\n",
    "    axes[1].text(32, -3, 'Details Lost ‚úó', ha='center', fontsize=10, color='red', weight='bold')\n",
    "    \n",
    "    # Show the problem\n",
    "    axes[2].text(0.5, 0.7, '‚ùå The Problem', ha='center', fontsize=16, weight='bold', \n",
    "                color='red', transform=axes[2].transAxes)\n",
    "    axes[2].text(0.5, 0.5, 'Need Large Receptive Field\\n‚Üì\\nUse Pooling\\n‚Üì\\nLose Resolution\\n‚Üì\\nCan\\'t Do Pixel-Precise Tasks!', \n",
    "                ha='center', va='center', fontsize=11, transform=axes[2].transAxes,\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüí° The Dilemma:\")\n",
    "    print(\"  ‚Ä¢ Semantic segmentation needs: Pixel-precise predictions\")\n",
    "    print(\"  ‚Ä¢ But also needs: Large receptive field to understand context\")\n",
    "    print(\"  ‚Ä¢ Pooling gives receptive field BUT destroys resolution\")\n",
    "    print(\"  ‚Ä¢ üéØ Solution: Dilated Convolutions!\")\n",
    "\n",
    "demonstrate_resolution_problem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db76699",
   "metadata": {},
   "source": [
    "## Part 2: Dilated Convolutions - The Solution\n",
    "\n",
    "Dilated convolutions insert \"holes\" (zeros) between kernel elements, exponentially expanding the receptive field WITHOUT pooling!\n",
    "\n",
    "**Regular 3√ó3 Conv**: Covers 3√ó3 pixels\n",
    "**Dilated Conv (rate=2)**: Covers 5√ó5 pixels (3√ó3 kernel with gaps)\n",
    "**Dilated Conv (rate=4)**: Covers 9√ó9 pixels (3√ó3 kernel with larger gaps)\n",
    "\n",
    "Let's visualize how this works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09713d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dilated convolutions\n",
    "def visualize_dilated_convolutions():\n",
    "    \"\"\"Show how dilated convolutions work.\"\"\"\n",
    "    \n",
    "    print(\"üëÅÔ∏è Visualizing Dilated Convolutions...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    \n",
    "    # Create a grid to show sampling pattern\n",
    "    grid_size = 11\n",
    "    \n",
    "    # Regular convolution (dilation=1)\n",
    "    ax = axes[0]\n",
    "    grid = np.zeros((grid_size, grid_size))\n",
    "    center = grid_size // 2\n",
    "    for i in range(-1, 2):\n",
    "        for j in range(-1, 2):\n",
    "            grid[center + i, center + j] = 1\n",
    "    \n",
    "    ax.imshow(grid, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "    ax.set_title('Regular Conv\\n(dilation=1)', fontsize=12, weight='bold')\n",
    "    ax.set_xlabel('Receptive Field: 3√ó3', fontsize=10)\n",
    "    ax.grid(True, which='both', color='gray', linewidth=0.5, alpha=0.3)\n",
    "    ax.set_xticks(np.arange(-0.5, grid_size, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-0.5, grid_size, 1), minor=True)\n",
    "    \n",
    "    # Dilated convolution (dilation=2)\n",
    "    ax = axes[1]\n",
    "    grid = np.zeros((grid_size, grid_size))\n",
    "    for i in range(-1, 2):\n",
    "        for j in range(-1, 2):\n",
    "            grid[center + i*2, center + j*2] = 1\n",
    "    \n",
    "    ax.imshow(grid, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "    ax.set_title('Dilated Conv\\n(dilation=2)', fontsize=12, weight='bold')\n",
    "    ax.set_xlabel('Receptive Field: 5√ó5', fontsize=10)\n",
    "    ax.grid(True, which='both', color='gray', linewidth=0.5, alpha=0.3)\n",
    "    ax.set_xticks(np.arange(-0.5, grid_size, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-0.5, grid_size, 1), minor=True)\n",
    "    \n",
    "    # Dilated convolution (dilation=4)\n",
    "    ax = axes[2]\n",
    "    grid = np.zeros((grid_size, grid_size))\n",
    "    for i in range(-1, 2):\n",
    "        for j in range(-1, 2):\n",
    "            grid[center + i*4, center + j*4] = 1\n",
    "    \n",
    "    ax.imshow(grid, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "    ax.set_title('Dilated Conv\\n(dilation=4)', fontsize=12, weight='bold')\n",
    "    ax.set_xlabel('Receptive Field: 9√ó9', fontsize=10)\n",
    "    ax.grid(True, which='both', color='gray', linewidth=0.5, alpha=0.3)\n",
    "    ax.set_xticks(np.arange(-0.5, grid_size, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-0.5, grid_size, 1), minor=True)\n",
    "    \n",
    "    # Comparison\n",
    "    ax = axes[3]\n",
    "    dilation_rates = [1, 2, 4, 8]\n",
    "    receptive_fields = [3, 5, 9, 17]\n",
    "    \n",
    "    ax.plot(dilation_rates, receptive_fields, 'bo-', linewidth=3, markersize=12)\n",
    "    ax.set_xlabel('Dilation Rate', fontsize=11, weight='bold')\n",
    "    ax.set_ylabel('Receptive Field Size', fontsize=11, weight='bold')\n",
    "    ax.set_title('Exponential Growth!', fontsize=12, weight='bold', color='green')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_yscale('log', base=2)\n",
    "    \n",
    "    for i, (d, rf) in enumerate(zip(dilation_rates, receptive_fields)):\n",
    "        ax.text(d, rf, f'{rf}√ó{rf}', ha='center', va='bottom', \n",
    "               fontsize=9, weight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüí° Key Insights:\")\n",
    "    print(\"  ‚úÖ Dilated conv = regular conv with gaps (holes)\")\n",
    "    print(\"  ‚úÖ Exponential receptive field growth: 3‚Üí5‚Üí9‚Üí17‚Üí33...\")\n",
    "    print(\"  ‚úÖ NO reduction in resolution!\")\n",
    "    print(\"  ‚úÖ NO additional parameters (same 3√ó3 kernel)\")\n",
    "    print(\"  ‚úÖ Perfect for dense prediction tasks!\")\n",
    "    \n",
    "    # Demonstrate with actual convolution\n",
    "    print(\"\\nüß™ Testing with PyTorch:\")\n",
    "    \n",
    "    x = torch.randn(1, 1, 32, 32)\n",
    "    \n",
    "    conv_regular = nn.Conv2d(1, 1, kernel_size=3, padding=1, dilation=1)\n",
    "    conv_dilated2 = nn.Conv2d(1, 1, kernel_size=3, padding=2, dilation=2)\n",
    "    conv_dilated4 = nn.Conv2d(1, 1, kernel_size=3, padding=4, dilation=4)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out_regular = conv_regular(x)\n",
    "        out_dilated2 = conv_dilated2(x)\n",
    "        out_dilated4 = conv_dilated4(x)\n",
    "    \n",
    "    print(f\"  Input shape: {list(x.shape)}\")\n",
    "    print(f\"  Regular conv (dilation=1): {list(out_regular.shape)}\")\n",
    "    print(f\"  Dilated conv (dilation=2): {list(out_dilated2.shape)}\")\n",
    "    print(f\"  Dilated conv (dilation=4): {list(out_dilated4.shape)}\")\n",
    "    print(\"  ‚úÖ All outputs maintain original resolution!\")\n",
    "\n",
    "visualize_dilated_convolutions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf3d7ab",
   "metadata": {},
   "source": [
    "## Part 3: Building Multi-Scale Feature Extraction with ASPP\n",
    "\n",
    "**ASPP (Atrous Spatial Pyramid Pooling)** applies dilated convolutions at multiple rates in parallel, then combines the results. This captures features at multiple scales simultaneously!\n",
    "\n",
    "Let's build and visualize ASPP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef93cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and explore ASPP module\n",
    "def explore_aspp():\n",
    "    \"\"\"Build and understand ASPP (Atrous Spatial Pyramid Pooling).\"\"\"\n",
    "    \n",
    "    print(\"üèóÔ∏è Building ASPP Module...\")\n",
    "    \n",
    "    # Create ASPP module\n",
    "    aspp = ASPPModule(in_channels=256, out_channels=256)\n",
    "    \n",
    "    print(\"\\nüìê ASPP Architecture:\")\n",
    "    print(aspp)\n",
    "    \n",
    "    # Test with input\n",
    "    x = torch.randn(1, 256, 32, 32)\n",
    "    \n",
    "    print(f\"\\nüß™ Testing ASPP:\")\n",
    "    print(f\"  Input shape: {list(x.shape)}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = aspp(x)\n",
    "    \n",
    "    print(f\"  Output shape: {list(output.shape)}\")\n",
    "    print(\"  ‚úÖ Resolution preserved!\")\n",
    "    \n",
    "    # Visualize ASPP architecture\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "    \n",
    "    # Input\n",
    "    ax.text(0.5, 0.95, 'Input Features\\n(256 channels, H√óW)', \n",
    "           ha='center', fontsize=12, weight='bold',\n",
    "           bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "    \n",
    "    # Parallel branches\n",
    "    branch_x = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    branch_names = ['1√ó1 Conv', 'Dilated Conv\\nrate=6', 'Dilated Conv\\nrate=12', \n",
    "                   'Dilated Conv\\nrate=18', 'Global\\nAvg Pool']\n",
    "    branch_colors = ['lightgreen', 'yellow', 'orange', 'salmon', 'lightcoral']\n",
    "    \n",
    "    for i, (x_pos, name, color) in enumerate(zip(branch_x, branch_names, branch_colors)):\n",
    "        # Draw branch\n",
    "        ax.arrow(0.5, 0.88, x_pos - 0.5, -0.15, \n",
    "                head_width=0.02, head_length=0.02, fc='gray', ec='gray', linewidth=1.5)\n",
    "        \n",
    "        # Branch operation\n",
    "        ax.add_patch(Rectangle((x_pos - 0.08, 0.55), 0.16, 0.15,\n",
    "                               facecolor=color, edgecolor='black', linewidth=2))\n",
    "        ax.text(x_pos, 0.625, name, ha='center', va='center', \n",
    "               fontsize=9, weight='bold')\n",
    "        \n",
    "        # Output arrow\n",
    "        ax.arrow(x_pos, 0.55, 0, -0.08, \n",
    "                head_width=0.02, head_length=0.02, fc='gray', ec='gray', linewidth=1.5)\n",
    "        \n",
    "        # Receptive field size\n",
    "        rf_sizes = ['3√ó3', '13√ó13', '25√ó25', '37√ó37', 'Global']\n",
    "        ax.text(x_pos, 0.42, f'RF: {rf_sizes[i]}', ha='center', \n",
    "               fontsize=8, style='italic', color='blue')\n",
    "    \n",
    "    # Concatenation\n",
    "    ax.add_patch(Rectangle((0.2, 0.25), 0.6, 0.1,\n",
    "                           facecolor='lightgray', edgecolor='black', linewidth=2))\n",
    "    ax.text(0.5, 0.3, 'Concatenate', ha='center', va='center', \n",
    "           fontsize=11, weight='bold')\n",
    "    \n",
    "    for x_pos in branch_x:\n",
    "        ax.arrow(x_pos, 0.35, 0.5 - x_pos, -0.08,\n",
    "                head_width=0.015, head_length=0.015, fc='gray', ec='gray', linewidth=1)\n",
    "    \n",
    "    # Final 1√ó1 conv\n",
    "    ax.arrow(0.5, 0.25, 0, -0.05,\n",
    "            head_width=0.02, head_length=0.02, fc='gray', ec='gray', linewidth=1.5)\n",
    "    \n",
    "    ax.add_patch(Rectangle((0.35, 0.08), 0.3, 0.1,\n",
    "                           facecolor='mediumpurple', edgecolor='black', linewidth=2))\n",
    "    ax.text(0.5, 0.13, '1√ó1 Conv\\n(Fuse Features)', ha='center', va='center',\n",
    "           fontsize=10, weight='bold')\n",
    "    \n",
    "    # Output\n",
    "    ax.arrow(0.5, 0.08, 0, -0.03,\n",
    "            head_width=0.02, head_length=0.015, fc='gray', ec='gray', linewidth=1.5)\n",
    "    \n",
    "    ax.text(0.5, 0.01, 'Output Features\\n(256 channels, H√óW)',\n",
    "           ha='center', fontsize=12, weight='bold',\n",
    "           bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
    "    \n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axis('off')\n",
    "    ax.set_title('ASPP: Multi-Scale Feature Extraction', fontsize=14, weight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüí° ASPP Benefits:\")\n",
    "    print(\"  ‚úÖ Captures features at multiple scales simultaneously\")\n",
    "    print(\"  ‚úÖ No resolution loss (unlike pyramid pooling)\")\n",
    "    print(\"  ‚úÖ Rich multi-scale context for each pixel\")\n",
    "    print(\"  ‚úÖ Critical for semantic segmentation!\")\n",
    "    \n",
    "    return aspp\n",
    "\n",
    "aspp_module = explore_aspp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae50c3",
   "metadata": {},
   "source": [
    "## Part 4: Receptive Field Growth Comparison\n",
    "\n",
    "Let's compare how receptive fields grow with different strategies: regular convolutions, pooling, and dilated convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5271422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare receptive field growth strategies\n",
    "def compare_receptive_field_growth():\n",
    "    \"\"\"Compare different strategies for growing receptive fields.\"\"\"\n",
    "    \n",
    "    print(\"üìä Comparing Receptive Field Growth Strategies...\")\n",
    "    \n",
    "    num_layers = 10\n",
    "    \n",
    "    # Strategy 1: Regular convolutions (kernel=3)\n",
    "    regular_rf = [1]\n",
    "    for i in range(num_layers):\n",
    "        regular_rf.append(regular_rf[-1] + 2)  # Each 3√ó3 conv adds 2\n",
    "    \n",
    "    # Strategy 2: With pooling (stride=2 every 2 layers)\n",
    "    pooling_rf = [1]\n",
    "    stride_factor = 1\n",
    "    for i in range(num_layers):\n",
    "        pooling_rf.append(pooling_rf[-1] + 2 * stride_factor)\n",
    "        if (i + 1) % 2 == 0:\n",
    "            stride_factor *= 2\n",
    "    \n",
    "    # Strategy 3: Dilated convolutions (exponential dilation)\n",
    "    dilated_rf = [1]\n",
    "    for i in range(num_layers):\n",
    "        dilation = 2 ** i\n",
    "        dilated_rf.append(dilated_rf[-1] + 2 * dilation)\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    layers = list(range(len(regular_rf)))\n",
    "    \n",
    "    # Linear plot\n",
    "    ax1.plot(layers, regular_rf, 'b-o', label='Regular Conv', linewidth=2, markersize=6)\n",
    "    ax1.plot(layers, pooling_rf, 'r-s', label='With Pooling', linewidth=2, markersize=6)\n",
    "    ax1.plot(layers, dilated_rf, 'g-^', label='Dilated Conv', linewidth=2, markersize=6)\n",
    "    \n",
    "    ax1.set_xlabel('Number of Layers', fontsize=12)\n",
    "    ax1.set_ylabel('Receptive Field Size', fontsize=12)\n",
    "    ax1.set_title('Receptive Field Growth (Linear Scale)', fontsize=13, weight='bold')\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Log plot\n",
    "    ax2.plot(layers, regular_rf, 'b-o', label='Regular Conv', linewidth=2, markersize=6)\n",
    "    ax2.plot(layers, pooling_rf, 'r-s', label='With Pooling', linewidth=2, markersize=6)\n",
    "    ax2.plot(layers, dilated_rf, 'g-^', label='Dilated Conv', linewidth=2, markersize=6)\n",
    "    \n",
    "    ax2.set_xlabel('Number of Layers', fontsize=12)\n",
    "    ax2.set_ylabel('Receptive Field Size (log scale)', fontsize=12)\n",
    "    ax2.set_title('Receptive Field Growth (Log Scale)', fontsize=13, weight='bold')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìà After 10 layers:\")\n",
    "    print(f\"  Regular Conv: {regular_rf[-1]}√ó{regular_rf[-1]} pixels\")\n",
    "    print(f\"  With Pooling: {pooling_rf[-1]}√ó{pooling_rf[-1]} pixels (but resolution reduced!)\")\n",
    "    print(f\"  Dilated Conv: {dilated_rf[-1]}√ó{dilated_rf[-1]} pixels (resolution intact!)\")\n",
    "    \n",
    "    print(\"\\nüí° Key Takeaway:\")\n",
    "    print(\"  üöÄ Dilated convolutions achieve EXPONENTIAL receptive field growth\")\n",
    "    print(\"  üéØ WITHOUT any resolution loss!\")\n",
    "    print(\"  ‚ö° Best of both worlds for dense prediction!\")\n",
    "\n",
    "compare_receptive_field_growth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa1ae8e",
   "metadata": {},
   "source": [
    "## Part 5: Semantic Segmentation with Dilated Convolutions\n",
    "\n",
    "Let's build a semantic segmentation network using dilated convolutions and test it on a segmentation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebef4858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train segmentation network\n",
    "def build_segmentation_network():\n",
    "    \"\"\"Build a semantic segmentation network with dilated convolutions.\"\"\"\n",
    "    \n",
    "    print(\"üé® Building Semantic Segmentation Network...\")\n",
    "    \n",
    "    # Simple segmentation network\n",
    "    class DilatedSegNet(nn.Module):\n",
    "        def __init__(self, num_classes=3):\n",
    "            super().__init__()\n",
    "            \n",
    "            # Encoder (no pooling!)\n",
    "            self.conv1 = nn.Conv2d(3, 64, 3, 1, 1)\n",
    "            self.bn1 = nn.BatchNorm2d(64)\n",
    "            \n",
    "            # Dilated convolution blocks\n",
    "            self.dilated1 = nn.Conv2d(64, 128, 3, 1, padding=1, dilation=1)\n",
    "            self.bn2 = nn.BatchNorm2d(128)\n",
    "            \n",
    "            self.dilated2 = nn.Conv2d(128, 128, 3, 1, padding=2, dilation=2)\n",
    "            self.bn3 = nn.BatchNorm2d(128)\n",
    "            \n",
    "            self.dilated4 = nn.Conv2d(128, 128, 3, 1, padding=4, dilation=4)\n",
    "            self.bn4 = nn.BatchNorm2d(128)\n",
    "            \n",
    "            self.dilated8 = nn.Conv2d(128, 256, 3, 1, padding=8, dilation=8)\n",
    "            self.bn5 = nn.BatchNorm2d(256)\n",
    "            \n",
    "            # ASPP-like multi-scale\n",
    "            self.aspp = ASPPModule(256, 256)\n",
    "            \n",
    "            # Decoder\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.Conv2d(256, 128, 3, 1, 1),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(128, 64, 3, 1, 1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(64, num_classes, 1)\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            # Encoder\n",
    "            x = F.relu(self.bn1(self.conv1(x)))\n",
    "            x = F.relu(self.bn2(self.dilated1(x)))\n",
    "            x = F.relu(self.bn3(self.dilated2(x)))\n",
    "            x = F.relu(self.bn4(self.dilated4(x)))\n",
    "            x = F.relu(self.bn5(self.dilated8(x)))\n",
    "            \n",
    "            # Multi-scale features\n",
    "            x = self.aspp(x)\n",
    "            \n",
    "            # Decoder\n",
    "            x = self.decoder(x)\n",
    "            \n",
    "            return x\n",
    "    \n",
    "    model = DilatedSegNet(num_classes=3).to(device)\n",
    "    \n",
    "    print(\"\\nüìê Model Architecture:\")\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"  Total parameters: {total_params:,}\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    test_input = torch.randn(2, 3, 128, 128).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(test_input)\n",
    "    \n",
    "    print(f\"\\nüß™ Forward Pass Test:\")\n",
    "    print(f\"  Input shape: {list(test_input.shape)}\")\n",
    "    print(f\"  Output shape: {list(output.shape)}\")\n",
    "    print(\"  ‚úÖ Resolution preserved: 128√ó128 ‚Üí 128√ó128\")\n",
    "    \n",
    "    # Create synthetic segmentation task\n",
    "    print(\"\\nüé® Creating segmentation dataset...\")\n",
    "    \n",
    "    # Simple synthetic data: three classes (background, object1, object2)\n",
    "    def create_segmentation_sample():\n",
    "        img = torch.randn(3, 128, 128) * 0.3\n",
    "        mask = torch.zeros(128, 128, dtype=torch.long)\n",
    "        \n",
    "        # Object 1 (circle)\n",
    "        y, x = torch.meshgrid(torch.arange(128), torch.arange(128), indexing='ij')\n",
    "        circle = ((x - 40)**2 + (y - 40)**2) < 400\n",
    "        mask[circle] = 1\n",
    "        img[:, circle] += 0.5\n",
    "        \n",
    "        # Object 2 (rectangle)\n",
    "        mask[70:100, 70:110] = 2\n",
    "        img[:, 70:100, 70:110] += 0.7\n",
    "        \n",
    "        return img, mask\n",
    "    \n",
    "    # Train for a few iterations\n",
    "    print(\"\\nüèãÔ∏è Training segmentation network...\")\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(20):\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for _ in range(10):  # 10 batches per epoch\n",
    "            # Generate batch\n",
    "            batch_imgs = []\n",
    "            batch_masks = []\n",
    "            for _ in range(4):\n",
    "                img, mask = create_segmentation_sample()\n",
    "                batch_imgs.append(img)\n",
    "                batch_masks.append(mask)\n",
    "            \n",
    "            batch_imgs = torch.stack(batch_imgs).to(device)\n",
    "            batch_masks = torch.stack(batch_masks).to(device)\n",
    "            \n",
    "            # Training step\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_imgs)\n",
    "            loss = criterion(outputs, batch_masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / 10\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"  Epoch {epoch+1}/20: Loss = {avg_loss:.4f}\")\n",
    "    \n",
    "    # Visualize training\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses, 'b-o', linewidth=2, markersize=6)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.title('Segmentation Training with Dilated Convolutions', fontsize=14, weight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ Training complete!\")\n",
    "    \n",
    "    # Test on a sample\n",
    "    print(\"\\nüé® Testing on sample image...\")\n",
    "    \n",
    "    model.eval()\n",
    "    test_img, test_mask = create_segmentation_sample()\n",
    "    test_img_batch = test_img.unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = model(test_img_batch)\n",
    "        pred_mask = pred.argmax(dim=1)[0].cpu()\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Input image\n",
    "    axes[0].imshow(test_img.permute(1, 2, 0) * 0.5 + 0.5)\n",
    "    axes[0].set_title('Input Image', fontsize=12, weight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Ground truth\n",
    "    axes[1].imshow(test_mask, cmap='tab10', vmin=0, vmax=9)\n",
    "    axes[1].set_title('Ground Truth Segmentation', fontsize=12, weight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Prediction\n",
    "    axes[2].imshow(pred_mask, cmap='tab10', vmin=0, vmax=9)\n",
    "    axes[2].set_title('Predicted Segmentation', fontsize=12, weight='bold')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüí° Key Achievement:\")\n",
    "    print(\"  ‚úÖ Pixel-precise predictions at full resolution\")\n",
    "    print(\"  ‚úÖ Multi-scale context from dilated convolutions\")\n",
    "    print(\"  ‚úÖ No information loss from pooling!\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "seg_model = build_segmentation_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128ee8a2",
   "metadata": {},
   "source": [
    "## Part 6: WaveNet - Dilated Convolutions in Audio\n",
    "\n",
    "Dilated convolutions aren't just for images! WaveNet used them to generate audio with huge temporal receptive fields. Let's explore this connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7e1c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore WaveNet-style dilated convolutions\n",
    "def explore_wavenet_dilations():\n",
    "    \"\"\"Understand how WaveNet uses dilated convolutions for audio.\"\"\"\n",
    "    \n",
    "    print(\"üéµ Dilated Convolutions in WaveNet (Audio)...\")\n",
    "    \n",
    "    # WaveNet uses exponentially increasing dilations\n",
    "    num_layers = 10\n",
    "    dilations = [2**i for i in range(num_layers)]\n",
    "    \n",
    "    print(\"\\nüìä WaveNet Dilation Schedule:\")\n",
    "    for i, d in enumerate(dilations):\n",
    "        print(f\"  Layer {i+1}: dilation = {d}\")\n",
    "    \n",
    "    # Calculate receptive field\n",
    "    receptive_field = 1\n",
    "    for d in dilations:\n",
    "        receptive_field += d * 2  # kernel_size = 3\n",
    "    \n",
    "    print(f\"\\nüéØ Total Receptive Field: {receptive_field} timesteps\")\n",
    "    \n",
    "    # Visualize the dilation schedule\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\n",
    "    \n",
    "    # Dilation growth\n",
    "    layers = list(range(1, num_layers + 1))\n",
    "    ax1.bar(layers, dilations, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "    ax1.set_xlabel('Layer', fontsize=12)\n",
    "    ax1.set_ylabel('Dilation Rate', fontsize=12)\n",
    "    ax1.set_title('WaveNet Dilation Schedule (Exponential Growth)', fontsize=14, weight='bold')\n",
    "    ax1.set_yscale('log', base=2)\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for i, (layer, dil) in enumerate(zip(layers, dilations)):\n",
    "        ax1.text(layer, dil, str(dil), ha='center', va='bottom', fontsize=9, weight='bold')\n",
    "    \n",
    "    # Receptive field visualization\n",
    "    ax2.text(0.5, 0.9, 'WaveNet Architecture', ha='center', fontsize=14, weight='bold',\n",
    "            transform=ax2.transAxes)\n",
    "    \n",
    "    y_pos = 0.75\n",
    "    for i, d in enumerate(dilations[:8]):  # Show first 8 layers\n",
    "        # Draw layer\n",
    "        ax2.text(0.1, y_pos, f'Layer {i+1}:', ha='right', fontsize=10,\n",
    "                transform=ax2.transAxes)\n",
    "        \n",
    "        # Draw dilation pattern\n",
    "        num_dots = min(20, 2**(i+1))\n",
    "        x_positions = np.linspace(0.15, 0.9, num_dots)\n",
    "        \n",
    "        # Show sampling pattern\n",
    "        for j in range(0, len(x_positions), d):\n",
    "            if j < len(x_positions):\n",
    "                ax2.plot(x_positions[j], y_pos, 'ro', markersize=8,\n",
    "                        transform=ax2.transAxes)\n",
    "        \n",
    "        # Connect samples\n",
    "        sample_positions = x_positions[::d][:3]  # Show first 3 samples\n",
    "        if len(sample_positions) >= 2:\n",
    "            ax2.plot(sample_positions, [y_pos]*len(sample_positions), \n",
    "                    'r--', alpha=0.5, linewidth=1, transform=ax2.transAxes)\n",
    "        \n",
    "        ax2.text(0.95, y_pos, f'dilation={d}', ha='left', fontsize=9,\n",
    "                style='italic', transform=ax2.transAxes)\n",
    "        \n",
    "        y_pos -= 0.08\n",
    "    \n",
    "    ax2.set_xlim(0, 1)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüí° WaveNet Insights:\")\n",
    "    print(f\"  ‚úÖ Exponential dilations: 1, 2, 4, 8, 16, 32, 64, 128, 256, 512\")\n",
    "    print(f\"  ‚úÖ Receptive field: {receptive_field} samples (~{receptive_field/16000:.3f}s at 16kHz)\")\n",
    "    print(\"  ‚úÖ Can 'hear' long-range dependencies\")\n",
    "    print(\"  ‚úÖ Generates realistic audio one sample at a time\")\n",
    "    print(\"  ‚úÖ Same principle as image segmentation!\")\n",
    "    \n",
    "    # Demonstrate 1D dilated convolution\n",
    "    print(\"\\nüß™ Testing 1D Dilated Convolution:\")\n",
    "    \n",
    "    # Create 1D signal\n",
    "    signal = torch.randn(1, 1, 100)\n",
    "    \n",
    "    conv1d_regular = nn.Conv1d(1, 1, kernel_size=3, padding=1, dilation=1)\n",
    "    conv1d_dilated = nn.Conv1d(1, 1, kernel_size=3, padding=4, dilation=4)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out_regular = conv1d_regular(signal)\n",
    "        out_dilated = conv1d_dilated(signal)\n",
    "    \n",
    "    print(f\"  Input signal: {list(signal.shape)}\")\n",
    "    print(f\"  Regular conv output: {list(out_regular.shape)}\")\n",
    "    print(f\"  Dilated conv output: {list(out_dilated.shape)}\")\n",
    "    print(\"  ‚úÖ Both preserve temporal resolution!\")\n",
    "\n",
    "explore_wavenet_dilations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe95400a",
   "metadata": {},
   "source": [
    "## Part 7: Your Turn to Experiment!\n",
    "\n",
    "Now it's your turn to explore dilated convolutions! Try different experiments and modifications.\n",
    "\n",
    "### Suggested Experiments:\n",
    "\n",
    "1. **Dilation Rates**: Test different dilation schedules (2, 4, 8 vs 1, 2, 3, 4)\n",
    "2. **Hybrid Networks**: Combine regular and dilated convolutions\n",
    "3. **Different Tasks**: Try on different dense prediction tasks\n",
    "4. **ASPP Variants**: Modify ASPP with different rates\n",
    "5. **3D Dilations**: Extend to volumetric data (video, medical imaging)\n",
    "\n",
    "Use the cell below for your experiments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e48fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experiment cell\n",
    "def my_dilated_conv_experiment():\n",
    "    \"\"\"Design your own dilated convolution experiment!\"\"\"\n",
    "    \n",
    "    print(\"üî¨ Your Custom Dilated Convolution Experiment\")\n",
    "    \n",
    "    # TODO: Design your experiment here!\n",
    "    # Ideas:\n",
    "    # - Test different dilation schedules\n",
    "    # - Build custom ASPP variants\n",
    "    # - Apply to different tasks\n",
    "    # - Compare with pooling-based approaches\n",
    "    \n",
    "    # Example: Test different dilation patterns\n",
    "    print(\"\\nüìä Comparing dilation patterns...\")\n",
    "    \n",
    "    patterns = {\n",
    "        'Linear': [1, 2, 3, 4, 5],\n",
    "        'Exponential': [1, 2, 4, 8, 16],\n",
    "        'Fibonacci': [1, 1, 2, 3, 5],\n",
    "        'Prime': [1, 2, 3, 5, 7]\n",
    "    }\n",
    "    \n",
    "    for name, dilations in patterns.items():\n",
    "        # Calculate receptive field\n",
    "        rf = 1\n",
    "        for d in dilations:\n",
    "            rf += 2 * d\n",
    "        \n",
    "        print(f\"  {name}: dilations={dilations}, RF={rf}√ó{rf}\")\n",
    "    \n",
    "    print(\"\\nüí° Your turn: Modify this cell to create your own experiments!\")\n",
    "    print(\"  Try building networks with different dilation patterns!\")\n",
    "    print(\"  Compare performance on segmentation tasks!\")\n",
    "\n",
    "# Run your experiment\n",
    "my_dilated_conv_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680672df",
   "metadata": {},
   "source": [
    "## Conclusions and Takeaways\n",
    "\n",
    "üéâ **Congratulations!** You've mastered dilated convolutions and multi-scale feature extraction!\n",
    "\n",
    "### Key Insights Discovered:\n",
    "\n",
    "1. **The Problem**: Pooling reduces resolution, bad for dense predictions\n",
    "2. **The Solution**: Dilated convolutions expand receptive field WITHOUT pooling\n",
    "3. **Exponential Growth**: Receptive field grows exponentially with layers\n",
    "4. **ASPP**: Multi-scale features captured in parallel\n",
    "5. **Universal Pattern**: Works for images (segmentation) AND audio (WaveNet)\n",
    "\n",
    "### The Magic of Dilated Convolutions:\n",
    "\n",
    "**Regular Conv**: Small receptive field, maintains resolution\n",
    "**Pooling**: Large receptive field, loses resolution ‚ùå\n",
    "**Dilated Conv**: Large receptive field, maintains resolution ‚úÖ\n",
    "\n",
    "### Why This Matters:\n",
    "\n",
    "- **Semantic Segmentation**: Pixel-precise predictions with global context\n",
    "- **Medical Imaging**: Detailed anatomical segmentation\n",
    "- **Autonomous Driving**: Scene understanding at every pixel\n",
    "- **Audio Generation**: WaveNet's realistic speech and music\n",
    "- **Video Analysis**: Temporal modeling without losing frames\n",
    "\n",
    "### The Core Principle:\n",
    "\n",
    "Dilated convolutions prove that **you don't need to sacrifice resolution for context**. By introducing gaps in convolutions, you can see both fine details AND the big picture simultaneously!\n",
    "\n",
    "### Modern Impact:\n",
    "\n",
    "Every state-of-art segmentation model uses dilated convolutions:\n",
    "- üéØ DeepLab (semantic segmentation champion)\n",
    "- üè• U-Net variants (medical imaging standard)\n",
    "- üöó Autonomous driving perception systems\n",
    "- üéµ WaveNet (audio generation breakthrough)\n",
    "- üìπ Video segmentation models\n",
    "\n",
    "### Key Equation:\n",
    "\n",
    "**Receptive Field with Dilation**:\n",
    "```\n",
    "RF = kernel_size + (kernel_size - 1) √ó (dilation - 1)\n",
    "```\n",
    "\n",
    "For 3√ó3 kernel:\n",
    "- dilation=1: RF = 3\n",
    "- dilation=2: RF = 5\n",
    "- dilation=4: RF = 9\n",
    "- dilation=8: RF = 17\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Explore DeepLab**: Study the complete architecture\n",
    "2. **Try Different Tasks**: Instance segmentation, panoptic segmentation\n",
    "3. **Audio Synthesis**: Implement WaveNet for music generation\n",
    "4. **Multi-modal**: Apply to video understanding\n",
    "\n",
    "The dilated convolution revolution shows that elegant mathematical insights - inserting \"holes\" in convolutions - can unlock entirely new capabilities! üéØüß†‚ú®"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
